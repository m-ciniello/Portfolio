{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment for Module 6\n",
    "\n",
    "In this assignment you will continue working with the housing price per district from the previous module assignment, this time training SVM models, both for regression and classification.\n",
    "\n",
    "#### Getting the data for the assignment (similar to the notebook from chapter 2 of Hands-On...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the categories in the categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {'<1H OCEAN':'LESS_1H_OCEAN', 'INLAND':'INLAND', 'ISLAND':'ISLAND', 'NEAR BAY':'NEAR_BAY', 'NEAR OCEAN':'NEAR_OCEAN'}\n",
    "housing['ocean_proximity'] = housing['ocean_proximity'].map(lambda s: d[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add 2 more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "median = housing[\"total_bedrooms\"].median()\n",
    "housing[\"total_bedrooms\"].fillna(median, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy variables based on the categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(housing['ocean_proximity'])\n",
    "housing = housing.drop('ocean_proximity', axis=1)\n",
    "housing = housing.join(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 16 columns):\n",
      "longitude                   20640 non-null float64\n",
      "latitude                    20640 non-null float64\n",
      "housing_median_age          20640 non-null float64\n",
      "total_rooms                 20640 non-null float64\n",
      "total_bedrooms              20640 non-null float64\n",
      "population                  20640 non-null float64\n",
      "households                  20640 non-null float64\n",
      "median_income               20640 non-null float64\n",
      "median_house_value          20640 non-null float64\n",
      "rooms_per_household         20640 non-null float64\n",
      "population_per_household    20640 non-null float64\n",
      "INLAND                      20640 non-null uint8\n",
      "ISLAND                      20640 non-null uint8\n",
      "LESS_1H_OCEAN               20640 non-null uint8\n",
      "NEAR_BAY                    20640 non-null uint8\n",
      "NEAR_OCEAN                  20640 non-null uint8\n",
      "dtypes: float64(11), uint8(5)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition into train and test\n",
    "\n",
    "Use train_test_split from sklearn.model_selection to partition the dataset into 70% for training and 30% for testing.\n",
    "\n",
    "You can use the 70% for training set as both training and validation by using cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'median_house_value'\n",
    "features = list(train_set.columns)\n",
    "features = [f for f in features if f!=target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr = train_set[features]\n",
    "y_tr = train_set[[target]]\n",
    "\n",
    "X_te = test_set[features]\n",
    "y_te = test_set[[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, use StandardScaler from sklearn.preprocessing to normalize the training and testing data, using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr = scaler.transform(X_tr)\n",
    "X_te = scaler.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression on original features (no transformations) --- benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [ 70142.55721218  67456.39127204  67318.3258893   70866.26065275]\n",
      "Mean: 68945.8837566\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_scores = cross_val_score(LinearRegression(), train_set[features], train_set[target], scoring=\"neg_mean_squared_error\", cv=4)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Support Vector Machines for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) In this exercise your goal is to tune SVR with FBR kernel, and make the average score mean_squared_error over 3-folds (cv=3) below 58000. \n",
    "\n",
    "You are encouraged to try optimizing any of the hyper-parameters of SVR\n",
    "\n",
    "See http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html for more details\n",
    "\n",
    "However, as a hint, you can focus on C and gamma. \n",
    "\n",
    "Hint 2: if when you try different values for a hyper-parameter, the optimal models corresponds to one of the extreme values in your range, that probably means you can keep improving your solution by considering values beyond the current range.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 35 candidates, totalling 105 fits\n",
      "[CV] C=40000, gamma=0.0525 ...........................................\n",
      "[CV] .. C=40000, gamma=0.0525, score=-3621965290.109213, total=   8.0s\n",
      "[CV] C=40000, gamma=0.0525 ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. C=40000, gamma=0.0525, score=-3469581685.289202, total=   8.4s\n",
      "[CV] C=40000, gamma=0.0525 ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   24.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. C=40000, gamma=0.0525, score=-3719586201.520208, total=   7.9s\n",
      "[CV] C=40000, gamma=0.053 ............................................\n",
      "[CV] ... C=40000, gamma=0.053, score=-3618952579.266771, total=   6.1s\n",
      "[CV] C=40000, gamma=0.053 ............................................\n",
      "[CV] ... C=40000, gamma=0.053, score=-3467334361.740825, total=   6.2s\n",
      "[CV] C=40000, gamma=0.053 ............................................\n",
      "[CV] ... C=40000, gamma=0.053, score=-3716968735.994022, total=   6.5s\n",
      "[CV] C=40000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=40000, gamma=0.0535, score=-3615307702.400349, total=   5.9s\n",
      "[CV] C=40000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=40000, gamma=0.0535, score=-3465403860.150068, total=   6.0s\n",
      "[CV] C=40000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=40000, gamma=0.0535, score=-3714444153.837089, total=   5.9s\n",
      "[CV] C=40000, gamma=0.054 ............................................\n",
      "[CV] ... C=40000, gamma=0.054, score=-3611331093.558772, total=   6.0s\n",
      "[CV] C=40000, gamma=0.054 ............................................\n",
      "[CV] ... C=40000, gamma=0.054, score=-3463036655.302365, total=   5.9s\n",
      "[CV] C=40000, gamma=0.054 ............................................\n",
      "[CV] ... C=40000, gamma=0.054, score=-3712296852.348317, total=   6.1s\n",
      "[CV] C=40000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=40000, gamma=0.0545, score=-3608355785.207087, total=   5.9s\n",
      "[CV] C=40000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=40000, gamma=0.0545, score=-3460619425.166240, total=   5.9s\n",
      "[CV] C=40000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=40000, gamma=0.0545, score=-3710204018.529644, total=   6.0s\n",
      "[CV] C=45000, gamma=0.0525 ...........................................\n",
      "[CV] .. C=45000, gamma=0.0525, score=-3597884238.507946, total=   5.9s\n",
      "[CV] C=45000, gamma=0.0525 ...........................................\n",
      "[CV] .. C=45000, gamma=0.0525, score=-3447311517.743312, total=   6.0s\n",
      "[CV] C=45000, gamma=0.0525 ...........................................\n",
      "[CV] .. C=45000, gamma=0.0525, score=-3699886493.164897, total=   5.9s\n",
      "[CV] C=45000, gamma=0.053 ............................................\n",
      "[CV] ... C=45000, gamma=0.053, score=-3594943035.746660, total=   5.9s\n",
      "[CV] C=45000, gamma=0.053 ............................................\n",
      "[CV] ... C=45000, gamma=0.053, score=-3444513809.880477, total=   6.0s\n",
      "[CV] C=45000, gamma=0.053 ............................................\n",
      "[CV] ... C=45000, gamma=0.053, score=-3697067279.396372, total=   6.7s\n",
      "[CV] C=45000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=45000, gamma=0.0535, score=-3592311370.611641, total=   6.1s\n",
      "[CV] C=45000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=45000, gamma=0.0535, score=-3442139486.680601, total=   6.6s\n",
      "[CV] C=45000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=45000, gamma=0.0535, score=-3694268377.408162, total=   6.0s\n",
      "[CV] C=45000, gamma=0.054 ............................................\n",
      "[CV] ... C=45000, gamma=0.054, score=-3590494611.942586, total=   6.2s\n",
      "[CV] C=45000, gamma=0.054 ............................................\n",
      "[CV] ... C=45000, gamma=0.054, score=-3440120426.193706, total=   5.9s\n",
      "[CV] C=45000, gamma=0.054 ............................................\n",
      "[CV] ... C=45000, gamma=0.054, score=-3691106224.755868, total=   6.0s\n",
      "[CV] C=45000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=45000, gamma=0.0545, score=-3588612743.300625, total=   6.2s\n",
      "[CV] C=45000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=45000, gamma=0.0545, score=-3437981380.367954, total=   6.2s\n",
      "[CV] C=45000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=45000, gamma=0.0545, score=-3687251691.445175, total=   6.3s\n",
      "[CV] C=50000, gamma=0.0525 ...........................................\n",
      "[CV] .. C=50000, gamma=0.0525, score=-3577418622.200929, total=   6.3s\n",
      "[CV] C=50000, gamma=0.0525 ...........................................\n",
      "[CV] .. C=50000, gamma=0.0525, score=-3426941065.924809, total=   6.3s\n",
      "[CV] C=50000, gamma=0.0525 ...........................................\n",
      "[CV] .. C=50000, gamma=0.0525, score=-3678283954.529109, total=   6.1s\n",
      "[CV] C=50000, gamma=0.053 ............................................\n",
      "[CV] ... C=50000, gamma=0.053, score=-3573851986.165344, total=   6.0s\n",
      "[CV] C=50000, gamma=0.053 ............................................\n",
      "[CV] ... C=50000, gamma=0.053, score=-3423189535.607076, total=   6.1s\n",
      "[CV] C=50000, gamma=0.053 ............................................\n",
      "[CV] ... C=50000, gamma=0.053, score=-3675403033.984654, total=   6.0s\n",
      "[CV] C=50000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=50000, gamma=0.0535, score=-3569744135.639548, total=   6.0s\n",
      "[CV] C=50000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=50000, gamma=0.0535, score=-3420058896.631976, total=   6.0s\n",
      "[CV] C=50000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=50000, gamma=0.0535, score=-3673325904.948489, total=   6.1s\n",
      "[CV] C=50000, gamma=0.054 ............................................\n",
      "[CV] ... C=50000, gamma=0.054, score=-3565505945.799904, total=   6.2s\n",
      "[CV] C=50000, gamma=0.054 ............................................\n",
      "[CV] ... C=50000, gamma=0.054, score=-3417688463.400327, total=   6.5s\n",
      "[CV] C=50000, gamma=0.054 ............................................\n",
      "[CV] ... C=50000, gamma=0.054, score=-3671407875.938538, total=   6.8s\n",
      "[CV] C=50000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=50000, gamma=0.0545, score=-3561557399.247418, total=   7.4s\n",
      "[CV] C=50000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=50000, gamma=0.0545, score=-3414884340.125837, total=   6.8s\n",
      "[CV] C=50000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=50000, gamma=0.0545, score=-3669329156.572194, total=   7.1s\n",
      "[CV] C=55000, gamma=0.0525 ...........................................\n",
      "[CV] .. C=55000, gamma=0.0525, score=-3553215831.188483, total=   7.5s\n",
      "[CV] C=55000, gamma=0.0525 ...........................................\n",
      "[CV] .. C=55000, gamma=0.0525, score=-3407560779.630049, total=   7.1s\n",
      "[CV] C=55000, gamma=0.0525 ...........................................\n",
      "[CV] .. C=55000, gamma=0.0525, score=-3660399437.011504, total=   7.7s\n",
      "[CV] C=55000, gamma=0.053 ............................................\n",
      "[CV] ... C=55000, gamma=0.053, score=-3550671541.674425, total=   7.2s\n",
      "[CV] C=55000, gamma=0.053 ............................................\n",
      "[CV] ... C=55000, gamma=0.053, score=-3404927212.359717, total=   6.6s\n",
      "[CV] C=55000, gamma=0.053 ............................................\n",
      "[CV] ... C=55000, gamma=0.053, score=-3658237178.095409, total=   6.2s\n",
      "[CV] C=55000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=55000, gamma=0.0535, score=-3548575329.931144, total=   6.2s\n",
      "[CV] C=55000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=55000, gamma=0.0535, score=-3402181831.620249, total=   6.2s\n",
      "[CV] C=55000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=55000, gamma=0.0535, score=-3656228593.251005, total=   6.3s\n",
      "[CV] C=55000, gamma=0.054 ............................................\n",
      "[CV] ... C=55000, gamma=0.054, score=-3545781530.709949, total=   6.4s\n",
      "[CV] C=55000, gamma=0.054 ............................................\n",
      "[CV] ... C=55000, gamma=0.054, score=-3400244128.341841, total=   6.3s\n",
      "[CV] C=55000, gamma=0.054 ............................................\n",
      "[CV] ... C=55000, gamma=0.054, score=-3653939770.327316, total=   6.4s\n",
      "[CV] C=55000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=55000, gamma=0.0545, score=-3543356347.026914, total=   6.2s\n",
      "[CV] C=55000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=55000, gamma=0.0545, score=-3398117235.556433, total=   6.1s\n",
      "[CV] C=55000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=55000, gamma=0.0545, score=-3651877155.752789, total=   6.5s\n",
      "[CV] C=60000, gamma=0.0525 ...........................................\n",
      "[CV] .. C=60000, gamma=0.0525, score=-3537805244.183455, total=   6.2s\n",
      "[CV] C=60000, gamma=0.0525 ...........................................\n",
      "[CV] .. C=60000, gamma=0.0525, score=-3393097529.376560, total=   6.5s\n",
      "[CV] C=60000, gamma=0.0525 ...........................................\n",
      "[CV] .. C=60000, gamma=0.0525, score=-3647799786.874353, total=   6.7s\n",
      "[CV] C=60000, gamma=0.053 ............................................\n",
      "[CV] ... C=60000, gamma=0.053, score=-3535349322.609411, total=   6.4s\n",
      "[CV] C=60000, gamma=0.053 ............................................\n",
      "[CV] ... C=60000, gamma=0.053, score=-3391351326.680353, total=   6.5s\n",
      "[CV] C=60000, gamma=0.053 ............................................\n",
      "[CV] ... C=60000, gamma=0.053, score=-3644695632.410586, total=   6.1s\n",
      "[CV] C=60000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=60000, gamma=0.0535, score=-3532361516.039949, total=   6.1s\n",
      "[CV] C=60000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=60000, gamma=0.0535, score=-3389233820.254920, total=   6.2s\n",
      "[CV] C=60000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=60000, gamma=0.0535, score=-3642589777.813181, total=   6.2s\n",
      "[CV] C=60000, gamma=0.054 ............................................\n",
      "[CV] ... C=60000, gamma=0.054, score=-3529357392.148735, total=   6.2s\n",
      "[CV] C=60000, gamma=0.054 ............................................\n",
      "[CV] ... C=60000, gamma=0.054, score=-3387128622.176843, total=   6.4s\n",
      "[CV] C=60000, gamma=0.054 ............................................\n",
      "[CV] ... C=60000, gamma=0.054, score=-3639938812.830275, total=   6.3s\n",
      "[CV] C=60000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=60000, gamma=0.0545, score=-3526310722.857846, total=   6.2s\n",
      "[CV] C=60000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=60000, gamma=0.0545, score=-3384661059.801128, total=   6.3s\n",
      "[CV] C=60000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=60000, gamma=0.0545, score=-3637011215.995167, total=   6.3s\n",
      "[CV] C=65000, gamma=0.0525 ...........................................\n",
      "[CV] .. C=65000, gamma=0.0525, score=-3522166304.742627, total=   6.4s\n",
      "[CV] C=65000, gamma=0.0525 ...........................................\n",
      "[CV] .. C=65000, gamma=0.0525, score=-3380119838.623628, total=   6.2s\n",
      "[CV] C=65000, gamma=0.0525 ...........................................\n",
      "[CV] .. C=65000, gamma=0.0525, score=-3632075309.779345, total=   6.2s\n",
      "[CV] C=65000, gamma=0.053 ............................................\n",
      "[CV] ... C=65000, gamma=0.053, score=-3519210390.684313, total=   6.1s\n",
      "[CV] C=65000, gamma=0.053 ............................................\n",
      "[CV] ... C=65000, gamma=0.053, score=-3377826922.530214, total=   6.1s\n",
      "[CV] C=65000, gamma=0.053 ............................................\n",
      "[CV] ... C=65000, gamma=0.053, score=-3629582052.621166, total=   6.3s\n",
      "[CV] C=65000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=65000, gamma=0.0535, score=-3516527122.298546, total=   6.2s\n",
      "[CV] C=65000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=65000, gamma=0.0535, score=-3375587464.116382, total=   6.2s\n",
      "[CV] C=65000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=65000, gamma=0.0535, score=-3627195205.584525, total=   6.1s\n",
      "[CV] C=65000, gamma=0.054 ............................................\n",
      "[CV] ... C=65000, gamma=0.054, score=-3513429108.080059, total=   6.1s\n",
      "[CV] C=65000, gamma=0.054 ............................................\n",
      "[CV] ... C=65000, gamma=0.054, score=-3372994182.348850, total=   6.2s\n",
      "[CV] C=65000, gamma=0.054 ............................................\n",
      "[CV] ... C=65000, gamma=0.054, score=-3624943540.276866, total=   6.2s\n",
      "[CV] C=65000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=65000, gamma=0.0545, score=-3510383701.728811, total=   6.2s\n",
      "[CV] C=65000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=65000, gamma=0.0545, score=-3370704971.141311, total=   6.1s\n",
      "[CV] C=65000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=65000, gamma=0.0545, score=-3622867141.519857, total=   6.3s\n",
      "[CV] C=70000, gamma=0.0525 ...........................................\n",
      "[CV] .. C=70000, gamma=0.0525, score=-3507204653.061223, total=   6.1s\n",
      "[CV] C=70000, gamma=0.0525 ...........................................\n",
      "[CV] .. C=70000, gamma=0.0525, score=-3367331399.644170, total=   6.1s\n",
      "[CV] C=70000, gamma=0.0525 ...........................................\n",
      "[CV] .. C=70000, gamma=0.0525, score=-3619723608.242021, total=   6.5s\n",
      "[CV] C=70000, gamma=0.053 ............................................\n",
      "[CV] ... C=70000, gamma=0.053, score=-3503919330.914338, total=   6.2s\n",
      "[CV] C=70000, gamma=0.053 ............................................\n",
      "[CV] ... C=70000, gamma=0.053, score=-3364607239.241959, total=   6.2s\n",
      "[CV] C=70000, gamma=0.053 ............................................\n",
      "[CV] ... C=70000, gamma=0.053, score=-3617149325.235462, total=   6.2s\n",
      "[CV] C=70000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=70000, gamma=0.0535, score=-3501023492.450900, total=   6.2s\n",
      "[CV] C=70000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=70000, gamma=0.0535, score=-3361560233.958455, total=   6.1s\n",
      "[CV] C=70000, gamma=0.0535 ...........................................\n",
      "[CV] .. C=70000, gamma=0.0535, score=-3614538469.998835, total=   6.2s\n",
      "[CV] C=70000, gamma=0.054 ............................................\n",
      "[CV] ... C=70000, gamma=0.054, score=-3498516962.450636, total=   6.1s\n",
      "[CV] C=70000, gamma=0.054 ............................................\n",
      "[CV] ... C=70000, gamma=0.054, score=-3359666455.765392, total=   6.1s\n",
      "[CV] C=70000, gamma=0.054 ............................................\n",
      "[CV] ... C=70000, gamma=0.054, score=-3611860408.905922, total=   6.0s\n",
      "[CV] C=70000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=70000, gamma=0.0545, score=-3495806872.445584, total=   6.2s\n",
      "[CV] C=70000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=70000, gamma=0.0545, score=-3357154267.518599, total=   6.1s\n",
      "[CV] C=70000, gamma=0.0545 ...........................................\n",
      "[CV] .. C=70000, gamma=0.0545, score=-3609838668.666263, total=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 105 out of 105 | elapsed: 16.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [40000, 45000, 50000, 55000, 60000, 65000, 70000], 'gamma': [0.0525, 0.053, 0.0535, 0.054, 0.0545]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_mean_squared_error', verbose=3)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "C_vals = [40000,45000,50000,55000,60000,65000,70000] ## YOUR VALUES FOR C ##\n",
    "gamma_vals = [0.0525,0.0530,0.0535,0.0540,0.0545] ## YOUR VALUES FOR gamma ## \n",
    "\n",
    "#use verbose=3 to see model progress and scores\n",
    "param_grid_rbf = [{'C':C_vals, 'gamma':gamma_vals}]\n",
    "grid_search_rbf = GridSearchCV(SVR(kernel='rbf'), param_grid_rbf, cv=3,verbose=3,scoring='neg_mean_squared_error')\n",
    "grid_search_rbf.fit(X_tr, np.ravel(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 70000, 'gamma': 0.0545}\n",
      "59055.9051765\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_rbf.best_params_)\n",
    "print(np.sqrt(-grid_search_rbf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] C=140000, gamma=0.058 ...........................................\n",
      "[CV] .. C=140000, gamma=0.058, score=-3358564651.413456, total=   6.9s\n",
      "[CV] C=140000, gamma=0.058 ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. C=140000, gamma=0.058, score=-3220592296.831881, total=   6.7s\n",
      "[CV] C=140000, gamma=0.058 ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   19.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. C=140000, gamma=0.058, score=-3485009394.334552, total=   6.8s\n",
      "[CV] C=140000, gamma=0.6 .............................................\n",
      "[CV] .... C=140000, gamma=0.6, score=-3334068503.167843, total=  19.1s\n",
      "[CV] C=140000, gamma=0.6 .............................................\n",
      "[CV] .... C=140000, gamma=0.6, score=-3188709698.179639, total=  17.8s\n",
      "[CV] C=140000, gamma=0.6 .............................................\n",
      "[CV] .... C=140000, gamma=0.6, score=-3372406025.769373, total=  21.4s\n",
      "[CV] C=140000, gamma=0.7 .............................................\n",
      "[CV] .... C=140000, gamma=0.7, score=-3413302468.757632, total=  22.4s\n",
      "[CV] C=140000, gamma=0.7 .............................................\n",
      "[CV] .... C=140000, gamma=0.7, score=-3266960091.804371, total=  26.4s\n",
      "[CV] C=140000, gamma=0.7 .............................................\n",
      "[CV] .... C=140000, gamma=0.7, score=-3443330800.536984, total=  20.1s\n",
      "[CV] C=145000, gamma=0.058 ...........................................\n",
      "[CV] .. C=145000, gamma=0.058, score=-3353380981.801385, total=   7.0s\n",
      "[CV] C=145000, gamma=0.058 ...........................................\n",
      "[CV] .. C=145000, gamma=0.058, score=-3213315921.722779, total=   6.9s\n",
      "[CV] C=145000, gamma=0.058 ...........................................\n",
      "[CV] .. C=145000, gamma=0.058, score=-3481031968.152800, total=   7.0s\n",
      "[CV] C=145000, gamma=0.6 .............................................\n",
      "[CV] .... C=145000, gamma=0.6, score=-3329841381.759232, total=  19.9s\n",
      "[CV] C=145000, gamma=0.6 .............................................\n",
      "[CV] .... C=145000, gamma=0.6, score=-3183806853.743334, total=  20.5s\n",
      "[CV] C=145000, gamma=0.6 .............................................\n",
      "[CV] .... C=145000, gamma=0.6, score=-3367824543.118488, total=  20.5s\n",
      "[CV] C=145000, gamma=0.7 .............................................\n",
      "[CV] .... C=145000, gamma=0.7, score=-3407983324.903872, total=  21.4s\n",
      "[CV] C=145000, gamma=0.7 .............................................\n",
      "[CV] .... C=145000, gamma=0.7, score=-3260719828.020471, total=  23.1s\n",
      "[CV] C=145000, gamma=0.7 .............................................\n",
      "[CV] .... C=145000, gamma=0.7, score=-3437310075.192559, total=  23.4s\n",
      "[CV] C=150000, gamma=0.058 ...........................................\n",
      "[CV] .. C=150000, gamma=0.058, score=-3349355158.127001, total=   6.9s\n",
      "[CV] C=150000, gamma=0.058 ...........................................\n",
      "[CV] .. C=150000, gamma=0.058, score=-3205027327.530904, total=   6.7s\n",
      "[CV] C=150000, gamma=0.058 ...........................................\n",
      "[CV] .. C=150000, gamma=0.058, score=-3477697002.593915, total=   6.8s\n",
      "[CV] C=150000, gamma=0.6 .............................................\n",
      "[CV] .... C=150000, gamma=0.6, score=-3326493823.496275, total=  23.2s\n",
      "[CV] C=150000, gamma=0.6 .............................................\n",
      "[CV] .... C=150000, gamma=0.6, score=-3179217931.138839, total=  18.2s\n",
      "[CV] C=150000, gamma=0.6 .............................................\n",
      "[CV] .... C=150000, gamma=0.6, score=-3363959227.760689, total=  25.3s\n",
      "[CV] C=150000, gamma=0.7 .............................................\n",
      "[CV] .... C=150000, gamma=0.7, score=-3403398834.056534, total=  23.8s\n",
      "[CV] C=150000, gamma=0.7 .............................................\n",
      "[CV] .... C=150000, gamma=0.7, score=-3254950972.434040, total=  23.1s\n",
      "[CV] C=150000, gamma=0.7 .............................................\n",
      "[CV] .... C=150000, gamma=0.7, score=-3431921339.479348, total=  24.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  8.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [140000, 145000, 150000], 'gamma': [0.058, 0.6, 0.7]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_mean_squared_error', verbose=3)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "C_vals = [140000,145000,150000] ## YOUR VALUES FOR C ##\n",
    "gamma_vals = [0.058,0.6,0.7] ## YOUR VALUES FOR gamma ## \n",
    "\n",
    "#use verbose=3 to see model progress and scores\n",
    "param_grid_rbf = [{'C':C_vals, 'gamma':gamma_vals}]\n",
    "grid_search_rbf = GridSearchCV(SVR(kernel='rbf'), param_grid_rbf, cv=3,verbose=3,scoring='neg_mean_squared_error')\n",
    "grid_search_rbf.fit(X_tr, np.ravel(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 150000, 'gamma': 0.6}\n",
      "57357.5655643\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_rbf.best_params_)\n",
    "print(np.sqrt(-grid_search_rbf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54952.9545466\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "final_model = grid_search_rbf.best_estimator_   ## THIS SHOULD BE THE BEST GRID_SEARCH ##\n",
    "\n",
    "y_te_estimation = final_model.predict(X_te)\n",
    "\n",
    "final_mse = mean_squared_error(y_te, y_te_estimation)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print(final_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaUAAAD8CAYAAADXJLslAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19a18da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(x=y_te, y=y_te_estimation)\n",
    "plt.xlim([-200000,800000])\n",
    "plt.ylim([-200000,800000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2. SVM for Classification\n",
    "\n",
    "Now we transform the continuous target into a binary variable, indicating whether or not the price is above the average $179700\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179700.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(housing[['median_house_value']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_tr_b = 1*np.ravel(y_tr>=179700.0)\n",
    "y_te_b = 1*np.ravel(y_te>=179700.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf = LinearSVC(random_state=42)\n",
    "lin_clf.fit(X_tr, y_tr_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83845514950166111"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lin_clf.predict(X_tr)\n",
    "accuracy_score(y_tr_b, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Does SVC (with default hyper-parameters) improve the performance of the linear SVM?\n",
    "\n",
    "Yes! The accuracy improves by about 3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]<bound method BaseEstimator.get_params of SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
      "  tol=0.001, verbose=10)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86614064230343302"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC rbd model\n",
    "svm_clf = SVC(random_state=42, kernel='rbf',verbose=10)\n",
    "svm_clf.fit(X_tr, y_tr_b)\n",
    "y_pred = svm_clf.predict(X_tr)\n",
    "print(svm_clf.get_params)\n",
    "accuracy_score(y_tr_b, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]<bound method BaseEstimator.get_params of SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
      "  tol=0.001, verbose=10)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85215946843853818"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC polynomial model\n",
    "svm_clf = SVC(random_state=42,kernel='poly', verbose=10)\n",
    "svm_clf.fit(X_tr, y_tr_b)\n",
    "y_pred = svm_clf.predict(X_tr)\n",
    "print(svm_clf.get_params)\n",
    "accuracy_score(y_tr_b, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Use randomized search to tune hyper-parameters of SVC and improve its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "from scipy.stats import randint as sp_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] C=7.79331215407, gamma=0.635143514433 ...........................\n",
      "[CV]  C=7.79331215407, gamma=0.635143514433, score=0.855917, total=   2.3s\n",
      "[CV] C=7.79331215407, gamma=0.635143514433 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=7.79331215407, gamma=0.635143514433, score=0.851585, total=   2.1s\n",
      "[CV] C=1.57201976455, gamma=0.44856843366 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    6.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1.57201976455, gamma=0.44856843366, score=0.864221, total=   1.9s\n",
      "[CV] C=1.57201976455, gamma=0.44856843366 ............................\n",
      "[CV]  C=1.57201976455, gamma=0.44856843366, score=0.857123, total=   1.9s\n",
      "[CV] C=4.31184580184, gamma=0.431243817008 ...........................\n",
      "[CV]  C=4.31184580184, gamma=0.431243817008, score=0.866298, total=   1.9s\n",
      "[CV] C=4.31184580184, gamma=0.431243817008 ...........................\n",
      "[CV]  C=4.31184580184, gamma=0.431243817008, score=0.857538, total=   2.0s\n",
      "[CV] C=7.74714123589, gamma=0.274284567704 ...........................\n",
      "[CV]  C=7.74714123589, gamma=0.274284567704, score=0.868789, total=   2.4s\n",
      "[CV] C=7.74714123589, gamma=0.274284567704 ...........................\n",
      "[CV]  C=7.74714123589, gamma=0.274284567704, score=0.859477, total=   1.9s\n",
      "[CV] C=18.2790808955, gamma=0.453337644397 ...........................\n",
      "[CV]  C=18.2790808955, gamma=0.453337644397, score=0.856886, total=   2.3s\n",
      "[CV] C=18.2790808955, gamma=0.453337644397 ...........................\n",
      "[CV]  C=18.2790808955, gamma=0.453337644397, score=0.852001, total=   2.1s\n",
      "[CV] C=14.6082097772, gamma=0.304524218055 ...........................\n",
      "[CV]  C=14.6082097772, gamma=0.304524218055, score=0.868235, total=   2.0s\n",
      "[CV] C=14.6082097772, gamma=0.304524218055 ...........................\n",
      "[CV]  C=14.6082097772, gamma=0.304524218055, score=0.861969, total=   1.9s\n",
      "[CV] C=9.00984977082, gamma=0.462096796402 ...........................\n",
      "[CV]  C=9.00984977082, gamma=0.462096796402, score=0.859654, total=   2.1s\n",
      "[CV] C=9.00984977082, gamma=0.462096796402 ...........................\n",
      "[CV]  C=9.00984977082, gamma=0.462096796402, score=0.855600, total=   2.0s\n",
      "[CV] C=4.47637572907, gamma=0.493395845904 ...........................\n",
      "[CV]  C=4.47637572907, gamma=0.493395845904, score=0.864637, total=   1.9s\n",
      "[CV] C=4.47637572907, gamma=0.493395845904 ...........................\n",
      "[CV]  C=4.47637572907, gamma=0.493395845904, score=0.855046, total=   1.9s\n",
      "[CV] C=12.9358729095, gamma=0.809768134403 ...........................\n",
      "[CV]  C=12.9358729095, gamma=0.809768134403, score=0.851488, total=   2.5s\n",
      "[CV] C=12.9358729095, gamma=0.809768134403 ...........................\n",
      "[CV]  C=12.9358729095, gamma=0.809768134403, score=0.849647, total=   2.3s\n",
      "[CV] C=2.31206339371, gamma=0.641114647544 ...........................\n",
      "[CV]  C=2.31206339371, gamma=0.641114647544, score=0.862699, total=   2.1s\n",
      "[CV] C=2.31206339371, gamma=0.641114647544 ...........................\n",
      "[CV]  C=2.31206339371, gamma=0.641114647544, score=0.854631, total=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   56.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, error_score='raise',\n",
       "          estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          fit_params={}, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000000000AA83358>, 'gamma': <scipy.stats._continuous_distns.uniform_gen object at 0x000000000A3481D0>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use verbose=3 to see model progress and scores\n",
    "param_dists = {'C':uniform(0.0001,20),'gamma':uniform}\n",
    "\n",
    "n_iter_search = 10\n",
    "\n",
    "rand_grid_search = RandomizedSearchCV(SVC(),\n",
    "                                      param_distributions=param_dists,\n",
    "                                      cv=2,\n",
    "                                      verbose=3,\n",
    "                                      n_iter=n_iter_search)\n",
    "\n",
    "rand_grid_search.fit(X_tr, y_tr_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 14.608209777187829, 'gamma': 0.30452421805491559}\n",
      "0.865102436323\n"
     ]
    }
   ],
   "source": [
    "print(rand_grid_search.best_params_)\n",
    "print(rand_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "\n",
    "Randomized search didn't seem to produce better results than the default parameters. However I can see how this would be useful for developing a model with many parameters as it gives you a good place to start, and you can then move to gridseachCV for more targeted fine tuning. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
