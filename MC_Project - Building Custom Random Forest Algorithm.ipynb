{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Recap\n",
    "\n",
    "In the last mission, we focused on increasing the number of attributes the model uses. We saw how, in general, **adding more attributes generally lowered the error of the model. This is because the model is able to do a better job identifying the living spaces from the training set that are the most similar to the ones from the test set.** However, **we also observed how using all of the available features didn't actually improve the model's accuracy automatically and that some of the features were probably not relevant for similarity ranking.** We learned that selecting relevant features was the right lever when improving a model's accuracy, not just increasing the features used in the absolute.\n",
    "\n",
    "In this mission, we'll focus on the impact of increasing k, the number of nearby neighbors the model uses to make predictions. We exported both the training (train_df) and test sets (test_df) from the last missions to CSV files, dc_airbnb_train.csv and dc_airbnb_test.csv respectively. Let's read both these CSV's into Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('dc_airbnb_train.csv')\n",
    "test_df = pd.read_csv('dc_airbnb_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Hyperparameter Optimization\n",
    "\n",
    "When we vary the features that are used in the model, we're affecting the data that the model uses. On the other hand, varying the k value affects the behavior of the model independently of the actual data that's used when making predictions. In other words, we're impacting how the model performs without trying to change the data that's used.\n",
    "\n",
    "Values that affect the behavior and performance of a model that are unrelated to the data that's used are referred to as hyperparameters. The process of finding the optimal hyperparameter value is known as hyperparameter optimization. A simple but common hyperparameter optimization technique is known as grid search, which involves:\n",
    "\n",
    "- selecting a subset of the possible hyperparameter values,\n",
    "- training a model using each of these hyperparameter values,\n",
    "- evaluating each model's performance,\n",
    "- selecting the hyperparameter value that resulted in the lowest error value.\n",
    "\n",
    "Grid search essentially boils down to evaluating the model performance at different k values and selecting the k value that resulted in the lowest error. While grid search can take a long time when working with large datasets, the data we're working with in this mission is small and this process is relatively quick.\n",
    "\n",
    "Let's confirm that grid search will work quickly for the dataset we're working with by first observing how the model performance changes as we increase the k value from 1 to 5. If you recall, we set 5 as the k value for the last 2 missions. Let's use the features from the last mission that resulted in the best model accuracy:\n",
    "\n",
    "    accommodates\n",
    "    bedrooms\n",
    "    bathrooms\n",
    "    number_of_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26364.928327645051,\n",
       " 15100.522468714449,\n",
       " 14578.804070281883,\n",
       " 15946.721060864618,\n",
       " 14119.735836177475]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']\n",
    "\n",
    "hyper_params = [1,2,3,4,5]\n",
    "mse_values = []\n",
    "\n",
    "for i in hyper_params:\n",
    "    knr = KNeighborsRegressor(n_neighbors=i,algorithm='brute')\n",
    "    knr.fit(train_df[features],train_df['price'])\n",
    "    predictions = knr.predict(test_df[features])\n",
    "    mse_values.append(mse(test_df['price'],predictions))\n",
    "    \n",
    "mse_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Expanding Grid Search\n",
    "Since our dataset is small and scikit-learn has been developed with performance in mind, the code ran quickly. As we increased the k value from 1 to 5, the MSE value fell from approximately 26364 to approximately 14090. Let's expand grid search all the way to a k value of 20. While 20 may seem like an arbitrary ending point for our grid search, we can always expand the values we try if we're unconvinced that the lowest MSE value is associated with one of the hyperparamter values we tried so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26364.928327645051,\n",
       " 15100.522468714449,\n",
       " 14578.804070281883,\n",
       " 15946.721060864618,\n",
       " 14119.735836177475,\n",
       " 13495.781569965869,\n",
       " 14209.360474565252,\n",
       " 14615.818988196814,\n",
       " 14591.371971516453,\n",
       " 14608.888509670078,\n",
       " 14747.643537453343,\n",
       " 14802.514876437872,\n",
       " 14726.607851848858,\n",
       " 14788.004486777645,\n",
       " 14775.071925167487,\n",
       " 14846.632372546928,\n",
       " 14801.420334526101,\n",
       " 14761.434233626876,\n",
       " 14750.644695086017,\n",
       " 14653.391259954493]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']\n",
    "\n",
    "hyper_params = list(range(1,21))\n",
    "mse_values = []\n",
    "\n",
    "for i in hyper_params:\n",
    "    knr = KNeighborsRegressor(n_neighbors=i,algorithm='brute')\n",
    "    knr.fit(train_df[features],train_df['price'])\n",
    "    predictions = knr.predict(test_df[features])\n",
    "    mse_values.append(mse(test_df['price'],predictions))\n",
    "    \n",
    "mse_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26364.928327645051,\n",
       " 15100.522468714449,\n",
       " 14578.804070281883,\n",
       " 15946.721060864618,\n",
       " 14119.735836177475,\n",
       " 13495.781569965869,\n",
       " 14209.360474565252,\n",
       " 14615.818988196814,\n",
       " 14591.371971516453,\n",
       " 14608.888509670078,\n",
       " 14747.643537453343,\n",
       " 14802.514876437872,\n",
       " 14726.607851848858,\n",
       " 14788.004486777645,\n",
       " 14775.071925167487,\n",
       " 14846.632372546928,\n",
       " 14801.420334526101,\n",
       " 14761.434233626876,\n",
       " 14750.644695086017,\n",
       " 14653.391259954493]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualizing Hyperparameter Values\n",
    "As we increased the k value from 1 to 6, the MSE value decreased from approximately 26364 to approximately 13657. However, as we increased the k value from 7 to 20, the MSE value didn't decrease further but instead hovered between approximately 14288 and 14870. This means that the optimal k value is 6, since it resulted in the lowest MSE value.\n",
    "\n",
    "This pattern is something you'll notice while performing grid search across other models as well. As you increase k at first, the error rate decreases until a certain point, but then rebounds and increases again. Let's confirm this behavior visually using a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw3CQJHUYDpKkDsNBktRhOEiSOv4/0fjs5NbirfwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xba77b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(hyper_params,mse_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Varying Features and Hyperparameters\n",
    "\n",
    "From the scatter plot, you can tell that the lowest MSE value was achieved at the k value of 6. As we increased k past 6, the MSE actually increased and hovered but never decreased below 13657 (the approximate MSE value when k was 6).\n",
    "\n",
    "Since varying the k value decreased the MSE value for this model, you may be wondering if repeating the grid search process for one of the models from the last mission that performed poorly when we fixed k to 5 would result in a lower MSE value. Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncJAkVQwHSVLFcJAkVf4f1Iz2OKr91ScAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb799c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyper_params = [x for x in range(1,21)]\n",
    "mse_values = list()\n",
    "features = train_df.columns.tolist()\n",
    "features.remove('price')\n",
    "\n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    mse_values.append(mse)\n",
    "\n",
    "plt.scatter(hyper_params, mse_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Practice the Workflow\n",
    "You may have noticed that the general workflow for finding the best model is:\n",
    "\n",
    "- select relevant features to use for predicting the target column.\n",
    "- use grid search to find the optimal hyperparameter value for the selected features.\n",
    "- evaluate the model's accuracy and repeat the process.\n",
    "\n",
    "Let's now practice this workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5.0: 14790.314266211606}\n",
      "{7.0: 13518.769009310208}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "two_features = ['accommodates', 'bathrooms']\n",
    "three_features = ['accommodates', 'bathrooms', 'bedrooms']\n",
    "hyper_params = list(range(1,21))\n",
    "\n",
    "# Append the first model's MSE values to this list.\n",
    "two_mse_values = list()\n",
    "for i in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=i,algorithm = 'brute')\n",
    "    knn.fit(train_df[two_features],train_df['price'])\n",
    "    predictions = knn.predict(test_df[two_features])\n",
    "    two_mse_values.append(mse(test_df['price'],predictions))\n",
    "\n",
    "mse_df=pd.DataFrame({'k':hyper_params,'mse_vals': two_mse_values})\n",
    "mse_df_sorted = mse_df.sort_values(by='mse_vals')\n",
    "two_hyp_mse = {mse_df_sorted.iloc[0][0]:mse_df_sorted.iloc[0][1]}\n",
    "\n",
    "# Append the second model's MSE values to this list.\n",
    "three_mse_values = list()\n",
    "for i in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=i,algorithm = 'brute')\n",
    "    knn.fit(train_df[three_features],train_df['price'])\n",
    "    predictions = knn.predict(test_df[three_features])\n",
    "    three_mse_values.append(mse(test_df['price'],predictions))\n",
    "\n",
    "mse_df=pd.DataFrame({'k':hyper_params,'mse_vals': three_mse_values})\n",
    "mse_df_sorted = mse_df.sort_values(by='mse_vals')\n",
    "three_hyp_mse = {mse_df_sorted.iloc[0][0]:mse_df_sorted.iloc[0][1]}\n",
    "\n",
    "print(two_hyp_mse)\n",
    "print(three_hyp_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Next Steps\n",
    "The first model, which used the accommodates and bathrooms columns, was able to achieve an MSE value of approximately 14790. The second model, which added the bedrooms column, was able to achieve an MSE value of approximately 13522.9, which is even lower than the lowest MSE value we achieved using the best model from the last mission (which used the accommodates, bedrooms, bathrooms, and number_of_reviews columns). Hopefully **this demonstrates that using just one lever to find the best model isn't enough and you really want to use both levers in conjunction.**\n",
    "\n",
    "In this mission, we learned about hyperparameter optimization and the workflow of finding the optimal model to make predictions. Next in this course is a challenge, where you'll practice the concepts you've learned so far on a completely new dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
