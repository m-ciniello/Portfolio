{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Basic Matrix Algebra\n",
    "\n",
    "Like vectors, matrices have their own set of algebraic operations. In this mission, we'll learn the core matrix operations and build up to using some of them to solve the matrix equation. Let's first start with matrix addition and subtraction.\n",
    "\n",
    "If you recall from the previous mission, a matrix consists of one or more column vectors.\n",
    "\n",
    "![](matrix_vector_decomposition.svg)\n",
    "\n",
    "Because of that, the operations from vectors also carry over to matrices. We could perform vector addition and subtraction between vectors with the same number of rows. We can perform matrix addition and subtraction between matrices containing the same number of rows and columns.\n",
    "\n",
    "![](valid_matrix_sums.svg)\n",
    "\n",
    "As with vectors, matrix addition and subtraction works by distributing the operations across the specific elements and combining them.\n",
    "\n",
    "![](matrix_addition.svg)\n",
    "\n",
    "Lastly, we can also multiply a matrix by a scalar value, just like we can with a vector.\n",
    "\n",
    "![](matrix_scalar_multiplication.svg)\n",
    "\n",
    "Let's practice applying these operators using NumPy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Matrix Vector Multiplication\n",
    "The matrix equation we discussed briefly in the last mission is an example of matrix-vector multiplication. When we multiply a matrix by a vector, we are essentially **combining each row in the matrix with the column vector.**\n",
    "\n",
    "![](matrix_vector_multiplication.svg)\n",
    "\n",
    "To multiply a matrix by a vector, the number of columns in the matrix needs to match the number of rows in the vector.\n",
    "\n",
    "![](valid_matrix_products.svg)\n",
    "\n",
    "To multiply a matrix with a vector in NumPy, we need to use the numpy.dot() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.69999999  3.          9.        ]\n",
      " [ 1.70000005  2.          9.        ]\n",
      " [ 0.69999999  9.          2.        ]] \n",
      "\n",
      "[[ 1.]\n",
      " [ 2.]\n",
      " [ 1.]] \n",
      "\n",
      "[[ 15.69999981]\n",
      " [ 14.69999981]\n",
      " [ 20.70000076]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix_a = np.asarray([\n",
    "    [0.7, 3, 9],\n",
    "    [1.7, 2, 9],\n",
    "    [0.7, 9, 2]\n",
    "], dtype=np.float32)\n",
    "print(matrix_a,'\\n')\n",
    "\n",
    "vector_b = np.asarray([\n",
    "    [1], [2], [1]\n",
    "], dtype=np.float32)\n",
    "print(vector_b,'\\n')\n",
    "\n",
    "ab_product = np.dot(matrix_a, vector_b)\n",
    "\n",
    "print(ab_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Matrix Multiplication\n",
    "\n",
    "Because a matrix consists of column vectors, we can extend what we learned about matrix vector multiplication to multiply matrices together. In matrix vector multiplication, we performed a dot product between each row in the matrix and the column vector. **In matrix multiplication, we extend this to perform a dot product between each row in the first matrix and each row in the second matrix.**\n",
    "\n",
    "![](matrix_multiplication.svg)\n",
    "\n",
    "As with matrix vector multiplication, the columns in the first matrix need to match the number of rows in the second matrix.\n",
    "\n",
    "![](valid_matrix_multiplication.svg)\n",
    "\n",
    "Note that the order of multiplication also matters.\n",
    "\n",
    "![](matrix_multiplication.svg)\n",
    "\n",
    "To multiply vectors in NumPy, we use the same numpy.dot() function we used in the last screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.69999999  3.        ]\n",
      " [ 1.70000005  2.        ]\n",
      " [ 0.69999999  9.        ]] \n",
      "\n",
      "[[ 113.    3.   10.]\n",
      " [   1.    0.    1.]] \n",
      "\n",
      "[[  82.09999847    2.0999999    10.        ]\n",
      " [ 194.1000061     5.10000038   19.        ]\n",
      " [  88.09999847    2.0999999    16.        ]] \n",
      "\n",
      "[[  91.19999695  435.        ]\n",
      " [   1.39999998   12.        ]]\n"
     ]
    }
   ],
   "source": [
    "matrix_a = np.asarray([\n",
    "    [0.7, 3],\n",
    "    [1.7, 2],\n",
    "    [0.7, 9]\n",
    "], dtype=np.float32)\n",
    "\n",
    "print(matrix_a,'\\n')\n",
    "\n",
    "matrix_b = np.asarray([\n",
    "    [113, 3, 10],\n",
    "    [1, 0, 1],\n",
    "], dtype=np.float32)\n",
    "\n",
    "print(matrix_b,'\\n')\n",
    "\n",
    "product_ab = np.dot(matrix_a, matrix_b)\n",
    "product_ba = np.dot(matrix_b, matrix_a)\n",
    "\n",
    "print(product_ab, '\\n')\n",
    "print(product_ba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Transpose Matrix\n",
    "\n",
    "The transpose of a matrix switches the rows and columns of a matrix. You can think of the transpose operation as a rotation. In data science, we're often working with data tables of different dimensions. Because of the requirements for matrix multiplication, we sometimes want to take the transpose of a matrix to allow us to multiply matrices together that, by default, don't overlap in number of rows and columns.\n",
    "\n",
    "Here's what the transpose of a matrix looks like visually:\n",
    "\n",
    "![](Matrix_transpose.gif)\n",
    "\n",
    "Mathematically, we use the notation AT to specify the transpose operation.\n",
    "\n",
    "$A^T + B^T = C$\n",
    "\n",
    "The transpose has a few different interesting rules that are a bit intuitive. For example, when taking the transpose of the sum of two matrices, we can distribute the transpose operation to each matrix:\n",
    "\n",
    "$(A+B)^T = A^T + B^T$\n",
    "\n",
    "One counterintuitive rule is when we take the transpose of the product of 2 matrices:\n",
    "\n",
    "$(AB)^T = B^TA^T$\n",
    "\n",
    "Let's explore these properties using NumPy. To compute the transpose of a NumPy ndarray, we need to use the numpy.transpose() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.69999999  3.        ]\n",
      " [ 1.70000005  2.        ]\n",
      " [ 0.69999999  9.        ]] \n",
      "\n",
      "[[  91.19999695    1.39999998]\n",
      " [ 435.           12.        ]] \n",
      "\n",
      "[[  82.09999847  194.1000061    88.09999847]\n",
      " [   2.0999999     5.10000038    2.0999999 ]\n",
      " [  10.           19.           16.        ]] \n",
      "\n",
      "[[  82.09999847  194.1000061    88.09999847]\n",
      " [   2.0999999     5.10000038    2.0999999 ]\n",
      " [  10.           19.           16.        ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "matrix_a = np.asarray([\n",
    "    [0.7, 3],\n",
    "    [1.7, 2],\n",
    "    [0.7, 9]\n",
    "], dtype=np.float32)\n",
    "\n",
    "matrix_b = np.asarray([\n",
    "    [113, 3, 10],\n",
    "    [1, 0, 1],\n",
    "], dtype=np.float32)\n",
    "\n",
    "\n",
    "transpose_a = np.transpose(matrix_a)\n",
    "print(np.transpose(transpose_a),'\\n')\n",
    "\n",
    "#A trans * B trans\n",
    "trans_ab = np.dot(np.transpose(matrix_a), np.transpose(matrix_b))\n",
    "print(trans_ab,'\\n')\n",
    "\n",
    "#B trans * A trans\n",
    "trans_ba = np.dot(np.transpose(matrix_b), np.transpose(matrix_a))\n",
    "print(trans_ba,'\\n')\n",
    "\n",
    "#A*B Transposed (should equal previous matrix!)\n",
    "product_ab = np.dot(matrix_a, matrix_b)\n",
    "print(np.transpose(product_ab),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Identity Matrix\n",
    "In the matrix equation that we discussed in the last mission, we're trying to solve for the vector x→.\n",
    "\n",
    "$A\\vec{x} = \\vec{b}$\n",
    "\n",
    "Right now, the matrix A multiplies the vector x→ and we need a way to cancel A.\n",
    "\n",
    "Let's look at the identity matrix, which we touched on briefly at the end of the first mission in this course. If you recall, the identity matrix contains 1 along the diagonals and 0 elsewhere. Here's what the 2x2 identity matrix looks like, often represented symbolically using I2:\n",
    "\n",
    "$I_2 = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$\n",
    "\n",
    "When we multiply I2 with any vector containing 2 elements, the resulting vector matches the original vector exactly:\n",
    "\n",
    "$I_2 \\vec{x} = \\vec{x}$\n",
    "\n",
    "This is because each element in the vector is multiplied exactly once by the diagonal 1 value in the identity matrix:\n",
    "\n",
    "![](identity_matrix.svg)\n",
    "\n",
    "**If we can transform matrix A and convert it into the identity matrix, then only the solution vector will remain $\\vec{x}$.** Let's practice working with the identity matrix before exploring how to transform A into I.\n",
    "\n",
    "We can create any In identity matrix using the numpy.identity() function. This function only has 1 required parameter, n, which specifies the n x n identity matrix we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]\n",
      " [ 7.  8.  9.]]\n",
      "[[  0.69999999   3.           1.        ]\n",
      " [  1.70000005   2.          10.        ]]\n"
     ]
    }
   ],
   "source": [
    "i_2 = np.identity(2)\n",
    "i_3 = np.identity(3)\n",
    "\n",
    "matrix_33 = np.asarray([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "\n",
    "matrix_23 = np.asarray([\n",
    "    [0.7, 3, 1],\n",
    "    [1.7, 2, 10],\n",
    "], dtype=np.float32)\n",
    "\n",
    "identity_33 = np.dot(i_3, matrix_33)\n",
    "identity_23 = np.dot(i_2, matrix_23)\n",
    "\n",
    "#We should expect identity_33 to match matrix_33 and identity_23 to match matrix_23.\n",
    "print(identity_33)\n",
    "print(identity_23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Matrix Inverse\n",
    "\n",
    "Now that we're more familiar with the identity matrix, let's discuss how to cancel the coefficient matrix A. Said another way, we want to transform A into the identity matrix I. Multiplying the inverse of a matrix by the matrix accomplishes this task.\n",
    "\n",
    "The matrix inverse is similar to the idea of the multiplicative inverse. For example, let's say we want to solve for x in the equation 5x=10. To do so, we need to multiply both sides by the multiplicative inverse of 5, which is 5^−1 (or 1/5):\n",
    "\n",
    "$5^{-1}*5x = 5^{-1}*10$\n",
    "\n",
    "The inverse of 5 transforms it to 1 and leaves us with the solution: x=2. To solve for the vector x→ in the matrix equation, we need to multiply both sides by the inverse of A:\n",
    "\n",
    "$A^{-1}A\\vec{x} = A^{-1}\\vec{b}$\n",
    "\n",
    "This simplifies to $I\\vec{x} = A^{-1}\\vec{b}$ and we're then left with the formula for calculating the solution vector:\n",
    "\n",
    "$\\vec{x} = A^{-1}\\vec{b}$\n",
    "\n",
    "While we use the matrix inverse to cancel out specific terms in the same fashion as the multiplicative inverse, the calculation is completely different. Let's understand the calculation for the inverse of a 2x2 matrix.\n",
    "\n",
    "If $A =  \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}$ then $A^{-1} = \\frac{1}{ad - bc} \\begin{bmatrix} d & -b \\\\ -c & a \\end{bmatrix}$.\n",
    "\n",
    "The term **ad−bc** is known as **the determinant** and is often written as $det(A) = ad - bc$ or as $|A| = ad - bc$. **Because we're dividing by the determinant when calculating the matrix inverse, a 2 x 2 matrix is only invertible if the determinant is not equal to 0**. In this step and the next step, we'll focus on finding the matrix inverse when A is a 2 x 2 matrix. Later in this mission, we'll walkthrough how to compute the matrix inverse for a higher dimensional matrix (3 x 3 and greater).\n",
    "\n",
    "Let's implement the matrix inverse in Python before moving on to solving the matrix equation.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "- Create a function named matrix_inverse_two() that accepts a 2 x 2 matrix, as a NumPy ndarray, and returns the matrix inverse.This function should first calculate the determinant of the matrix.\n",
    "  - If the determinant is equal to 0, an error should be returned.\n",
    "  - If the determinant is not equal to 0, this function should return the matrix inverse.\n",
    "- Calculate the inverse of matrix_a using the function you just wrote and assign the result to inverse_a.\n",
    "- Multiply inverse_a with matrix_a and assign the result to i_2. Display i_2 using the print() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "matrix_a = np.asarray([\n",
    "    [1.5, 3],\n",
    "    [1, 4]\n",
    "])\n",
    "# create function that returns invesrse of matrix\n",
    "def matrix_inverse_two(mat):\n",
    "    det = (mat[0,0]*mat[1,1] - mat[0,1]*mat[1,0])\n",
    "    if det == 0:\n",
    "        raise ValueError(\"The matrix isn't invertible\")\n",
    "    right_mat = np.asarray([\n",
    "        [mat[1,1], -mat[0,1]],\n",
    "        [-mat[1,0], mat[0,0]]\n",
    "    ])\n",
    "    inv_mat = np.dot(1/det, right_mat)\n",
    "    return inv_mat\n",
    "\n",
    "inverse_a = matrix_inverse_two(matrix_a)\n",
    "\n",
    "i_2 = np.dot(inverse_a, matrix_a)\n",
    "print(i_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Solving The Matrix Equation\n",
    "Now that we know how to compute the matrix inverse, we can solve our system using the matrix equation $A\\vec{x} = \\vec{b}$:\n",
    "\n",
    "$\\left[\\begin{array}{rr|r}\n",
    "30 & -1 \\\\ \n",
    "50 & -1 \n",
    "\\end{array}\\right] \\begin{bmatrix} x_1\\\\ x_2 \\end{bmatrix} =  \\begin{bmatrix} -1000\\\\ -100 \\end{bmatrix}$\n",
    "\n",
    "We start by left multiplying A^−1 on both sides:\n",
    "\n",
    "$\\left[\\begin{array}{rr|r}\n",
    "30 & -1 \\\\ \n",
    "50 & -1 \n",
    "\\end{array}\\right]^{-1} \\left[\\begin{array}{rr|r}\n",
    "30 & -1 \\\\ \n",
    "50 & -1 \n",
    "\\end{array}\\right] \\begin{bmatrix} x_1\\\\ x_2 \\end{bmatrix} =  \\left[\\begin{array}{rr|r}\n",
    "30 & -1 \\\\ \n",
    "50 & -1 \n",
    "\\end{array}\\right]^{-1} \\begin{bmatrix} -1000\\\\ -100 \\end{bmatrix}$\n",
    "\n",
    "This simplifies to:\n",
    "\n",
    "$\\begin{bmatrix} x_1\\\\ x_2 \\end{bmatrix} =  \\left[\\begin{array}{rr|r}\n",
    "30 & -1 \\\\ \n",
    "50 & -1 \n",
    "\\end{array}\\right]^{-1} \\begin{bmatrix} -1000\\\\ -100 \\end{bmatrix}$\n",
    "\n",
    "Let's finish this last step in Python. To compute the inverse of a NumPy ndarray, we need to use the numpy.linalg.inv() function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   45.]\n",
      " [ 2350.]]\n"
     ]
    }
   ],
   "source": [
    "matrix_a = np.asarray([\n",
    "    [30, -1],\n",
    "    [50, -1]\n",
    "])\n",
    "\n",
    "vector_b = np.asarray([\n",
    "    [-1000],\n",
    "    [-100]\n",
    "])\n",
    "\n",
    "#use the np.linalg.inv function to do this!!!\n",
    "matrix_a_inverse = np.linalg.inv(matrix_a)\n",
    "solution_x = np.dot(matrix_a_inverse, vector_b)\n",
    "print(solution_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Determinant for Higher Dimensions\n",
    "\n",
    "Before we discuss how to compute the matrix inverse for higher dimensional matrices, let's dive deeper into the determinant and introduce some more terminology. So far, we've mostly worked with matrices that contain the same number orws and columns. These matrices are known as square matrices and we can only compute the determinant and matrix inverse for square matrices. In addition, **we can only compute the matrix inverse of a square matrix when the determinant is not equal to 0.** (ONLY A SQUARE!?!? REALLY?!?! SO HOW USEFUL IS THIS TECHNIQUE?!?! I DONT REALLY KNOW YET TBH...)\n",
    "\n",
    "To find the determinant of a higher dimensional square matrix, we need use the more general form of the determinant. Here's what that looks like:\n",
    "\n",
    "![](3d_determinant_one.svg)\n",
    "\n",
    "The determinant of a higher-dimensional system involves breaking down the full matrix into **minor matrices.** First, we select a row or column (most teaching materials select the first row). For the first value in that row, we \"hide\" the other values in that row (2nd and 3rd value in the row) and in that column (2nd and 3rd value in the column), select the rest of the elements as the minor matrix, and multiply the scalar value with the determinant of the minor matrix. We repeat this for the remaining values in the first row. This diagram helps illustrate this much clearer:\n",
    "\n",
    "![](3d_determinant_two.svg)\n",
    "\n",
    "Here's a concrete example:\n",
    "\n",
    "![](3d_determinant_three.svg)\n",
    "\n",
    "To compute the determinant in NumPy, we use the *numpy.linalg.det()* function. We'll leave it to you to read the documentation and learn how to use this function.\n",
    "\n",
    "*ALSO REMEMBER THAT WHEN YOU MULTIPLE THE MINOR MATRICES BY A, B, or C, YOU HAVE TO CHANGE THEIR SIGNS TO MATCH THE FOLLOWING:*\n",
    "![](POST_NEG.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "-9.51619735393e-16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[64, 16],\n",
       "       [16,  4]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_22 = np.asarray([\n",
    "    [8, 4],\n",
    "    [4, 2]\n",
    "])\n",
    "\n",
    "matrix_33 = np.asarray([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "det_22 = np.linalg.det(matrix_22)\n",
    "det_33 = np.linalg.det(matrix_33)\n",
    "\n",
    "print(det_22)\n",
    "print(det_33)\n",
    "\n",
    "matrix_22*matrix_22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Matrix Inverse for Higher Dimensions\n",
    "To calculate the matrix inverse for a 3 by 3, or larger, matrix, we need to also work with the more general form of the matrix inverse equation. Similar to the determinant for higher-dimensional matrices, the matrix inverse works by generating minor matrices that are dependent on the position in the matrix. Here's a diagram describing the matrix inverse for a 3 by 3 matrix:\n",
    "\n",
    "![](3d_matrix_inverse.svg)\n",
    "\n",
    "While it's helpful to know how to compute the inverse this way for higher dimensional matrices, the amount of careful arithmetic you have to by hand is large. Thankfully, the numpy.linalg.inv() function can work with any n-dimensional square matrix.\n",
    "\n",
    "\n",
    "**THIS IS A PRETTY SIMPLE, BUT METICULOUS PROCESS. THIS SITE HAS SOME GREAT EXAMPLES. You probably just need to get the basic process, because software will do this for you very quickly (as seen below!)**\n",
    "\n",
    "https://www.mathsisfun.com/algebra/matrix-inverse-minors-cofactors-adjugate.html\n",
    "![](matrix-gauss-jordan3.gif)\n",
    "*above is the original matrix\n",
    "![](matrix-minors2.svg)\n",
    "*This is the determinents of all the 'minor matrices'\n",
    "![](matrix-adjugate-inverse.SVG)\n",
    "*Ten is the determinant of A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2  0.2  0. ]\n",
      " [-0.2  0.3  1. ]\n",
      " [ 0.2 -0.3  0. ]] \n",
      "\n",
      "LOOK! IT SHOULD PRODUCE THE EXACT SAME MATRIX FROM THE EXAMPLE ABOVE\n"
     ]
    }
   ],
   "source": [
    "matrix_a = np.asarray([\n",
    "    [3,0,2],\n",
    "    [2,0,-2],\n",
    "    [0,1,1]\n",
    "])\n",
    "\n",
    "#use the inverse formula to calucalte\n",
    "matrix_a_inverse = np.linalg.inv(matrix_a)\n",
    "print(matrix_a_inverse,'\\n')\n",
    "\n",
    "print('LOOK! IT SHOULD PRODUCE THE EXACT SAME MATRIX FROM THE EXAMPLE ABOVE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Next Steps\n",
    "\n",
    "In this mission, we learned about the different matrix operations and how to solve a linear system that's represented using the matrix equation using the matrix inverse. In the next mission, we'll learn the different ways a solution set can be represented and how to calculate the determinant of a higher dimensional matrix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
