{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "To understand how linear regression works, we've stuck to using features from the training dataset that contained no missing values and were already in a convenient numeric representation. In this mission, we'll explore how to transform some of the the remaining features so we can use them in our model. <font color=green> Broadly, the process of processing and creating new features is known as feature engineering. Feature engineering is a bit of an art and having knowledge in the specific domain (in this case real estate) can help you create better features.</font> In this mission, we'll focus on some domain-independent strategies that work for all problems.\n",
    "\n",
    "In the first half of this mission, we'll focus only on columns that contain no missing values but still aren't in the proper format to use in a linear regression model. In the latter half of this mission, we'll explore some ways to deal with missing values.\n",
    "\n",
    "Amongst the columns that don't contain missing values, some of the common issues include:\n",
    "\n",
    "- the column is not numerical (e.g. a zoning code represented using text)\n",
    "- the column is numerical but not ordinal (e.g. zip code values)\n",
    "- the column is numerical but isn't representative of the type of relationship with the target column (e.g. year values)\n",
    "\n",
    "Let's start by filtering the training set to just the columns containing no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order                0\n",
      "PID                  0\n",
      "MS SubClass          0\n",
      "MS Zoning            0\n",
      "Lot Frontage       249\n",
      "Lot Area             0\n",
      "Street               0\n",
      "Alley             1351\n",
      "Lot Shape            0\n",
      "Land Contour         0\n",
      "Utilities            0\n",
      "Lot Config           0\n",
      "Land Slope           0\n",
      "Neighborhood         0\n",
      "Condition 1          0\n",
      "Condition 2          0\n",
      "Bldg Type            0\n",
      "House Style          0\n",
      "Overall Qual         0\n",
      "Overall Cond         0\n",
      "Year Built           0\n",
      "Year Remod/Add       0\n",
      "Roof Style           0\n",
      "Roof Matl            0\n",
      "Exterior 1st         0\n",
      "Exterior 2nd         0\n",
      "Mas Vnr Type        11\n",
      "Mas Vnr Area        11\n",
      "Exter Qual           0\n",
      "Exter Cond           0\n",
      "                  ... \n",
      "Bedroom AbvGr        0\n",
      "Kitchen AbvGr        0\n",
      "Kitchen Qual         0\n",
      "TotRms AbvGrd        0\n",
      "Functional           0\n",
      "Fireplaces           0\n",
      "Fireplace Qu       717\n",
      "Garage Type         74\n",
      "Garage Yr Blt       75\n",
      "Garage Finish       75\n",
      "Garage Cars          0\n",
      "Garage Area          0\n",
      "Garage Qual         75\n",
      "Garage Cond         75\n",
      "Paved Drive          0\n",
      "Wood Deck SF         0\n",
      "Open Porch SF        0\n",
      "Enclosed Porch       0\n",
      "3Ssn Porch           0\n",
      "Screen Porch         0\n",
      "Pool Area            0\n",
      "Pool QC           1459\n",
      "Fence             1163\n",
      "Misc Feature      1400\n",
      "Misc Val             0\n",
      "Mo Sold              0\n",
      "Yr Sold              0\n",
      "Sale Type            0\n",
      "Sale Condition       0\n",
      "SalePrice            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('AmesHousing3.txt', delimiter=\"\\t\")\n",
    "train = data[0:1460]\n",
    "test = data[1460:]\n",
    "\n",
    "train_null_counts = train.isnull().sum()\n",
    "print(train_null_counts)\n",
    "df_no_mv = train[train_null_counts[train_null_counts==0].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 58 columns):\n",
      "Order              1460 non-null int64\n",
      "PID                1460 non-null int64\n",
      "MS SubClass        1460 non-null int64\n",
      "MS Zoning          1460 non-null object\n",
      "Lot Area           1460 non-null int64\n",
      "Street             1460 non-null object\n",
      "Lot Shape          1460 non-null object\n",
      "Land Contour       1460 non-null object\n",
      "Utilities          1460 non-null object\n",
      "Lot Config         1460 non-null object\n",
      "Land Slope         1460 non-null object\n",
      "Neighborhood       1460 non-null object\n",
      "Condition 1        1460 non-null object\n",
      "Condition 2        1460 non-null object\n",
      "Bldg Type          1460 non-null object\n",
      "House Style        1460 non-null object\n",
      "Overall Qual       1460 non-null int64\n",
      "Overall Cond       1460 non-null int64\n",
      "Year Built         1460 non-null int64\n",
      "Year Remod/Add     1460 non-null int64\n",
      "Roof Style         1460 non-null object\n",
      "Roof Matl          1460 non-null object\n",
      "Exterior 1st       1460 non-null object\n",
      "Exterior 2nd       1460 non-null object\n",
      "Exter Qual         1460 non-null object\n",
      "Exter Cond         1460 non-null object\n",
      "Foundation         1460 non-null object\n",
      "Heating            1460 non-null object\n",
      "Heating QC         1460 non-null object\n",
      "Central Air        1460 non-null object\n",
      "Electrical         1460 non-null object\n",
      "1st Flr SF         1460 non-null int64\n",
      "2nd Flr SF         1460 non-null int64\n",
      "Low Qual Fin SF    1460 non-null int64\n",
      "Gr Liv Area        1460 non-null int64\n",
      "Full Bath          1460 non-null int64\n",
      "Half Bath          1460 non-null int64\n",
      "Bedroom AbvGr      1460 non-null int64\n",
      "Kitchen AbvGr      1460 non-null int64\n",
      "Kitchen Qual       1460 non-null object\n",
      "TotRms AbvGrd      1460 non-null int64\n",
      "Functional         1460 non-null object\n",
      "Fireplaces         1460 non-null int64\n",
      "Garage Cars        1460 non-null float64\n",
      "Garage Area        1460 non-null float64\n",
      "Paved Drive        1460 non-null object\n",
      "Wood Deck SF       1460 non-null int64\n",
      "Open Porch SF      1460 non-null int64\n",
      "Enclosed Porch     1460 non-null int64\n",
      "3Ssn Porch         1460 non-null int64\n",
      "Screen Porch       1460 non-null int64\n",
      "Pool Area          1460 non-null int64\n",
      "Misc Val           1460 non-null int64\n",
      "Mo Sold            1460 non-null int64\n",
      "Yr Sold            1460 non-null int64\n",
      "Sale Type          1460 non-null object\n",
      "Sale Condition     1460 non-null object\n",
      "SalePrice          1460 non-null int64\n",
      "dtypes: float64(2), int64(28), object(28)\n",
      "memory usage: 661.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_no_mv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Categorical Features\n",
    "\n",
    "You'll notice that some of the columns in the data frame df_no_mv contain string values. If these columns contain only a limited set of uniuqe values, they're known as categorical features. As the name suggests, a categorical feature groups a specific training example into a specific category. Here are some examples from the dataset:\n",
    "\n",
    "    >>>train['Utilities'].value_counts()\n",
    "    AllPub    1457\n",
    "    NoSewr       2\n",
    "    NoSeWa       1\n",
    "    Name: Utilities, dtype: int64\n",
    "\n",
    "    >>> train['Street'].value_counts()\n",
    "    Pave    1455\n",
    "    Grvl       5\n",
    "\n",
    "    >>> train['House Style'].value_counts()\n",
    "    1Story    743\n",
    "    2Story    440\n",
    "    1.5Fin    160\n",
    "    SLvl       60\n",
    "    SFoyer     35\n",
    "    2.5Unf     11\n",
    "    1.5Unf      8\n",
    "    2.5Fin      3\n",
    "\n",
    "To use these features in our model, we need to transform them into numerical representations. **Thankfully, pandas makes this easy because the library has a special categorical data type. We can convert any column that contains *no missing values (or an error will be thrown)* to the categorical data type using the pandas.Series.astype() method:**\n",
    "\n",
    "    >>> train['Utilities'] = train['Utilities'].astype('category')\n",
    "\n",
    "When a column is converted to the categorical data type, pandas assigns a code to each unique value in the column. Unless we access these values directly, most of the pandas manipulation operations that work for string columns will work for categorical ones as well.\n",
    "\n",
    "    >>> train['Utilities']\n",
    "    0       AllPub\n",
    "    1       AllPub\n",
    "    2       AllPub\n",
    "    3       AllPub\n",
    "    4       AllPub\n",
    "    5       AllPub\n",
    "    ...\n",
    "\n",
    "We need to use the .cat accessor followed by the .codes property to actually access the underlying numerical representation of a column:\n",
    "\n",
    "    >>> train['Utilities'].cat.codes\n",
    "\n",
    "Let's convert all of the text columns that contain no missing values into the categorical data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS Zoning: 6\n",
      "Street: 2\n",
      "Lot Shape: 4\n",
      "Land Contour: 4\n",
      "Utilities: 3\n",
      "Lot Config: 5\n",
      "Land Slope: 3\n",
      "Neighborhood: 26\n",
      "Condition 1: 9\n",
      "Condition 2: 6\n",
      "Bldg Type: 5\n",
      "House Style: 8\n",
      "Roof Style: 6\n",
      "Roof Matl: 5\n",
      "Exterior 1st: 14\n",
      "Exterior 2nd: 16\n",
      "Exter Qual: 4\n",
      "Exter Cond: 5\n",
      "Foundation: 6\n",
      "Heating: 6\n",
      "Heating QC: 4\n",
      "Central Air: 2\n",
      "Electrical: 4\n",
      "Kitchen Qual: 5\n",
      "Functional: 7\n",
      "Paved Drive: 3\n",
      "Sale Type: 9\n",
      "Sale Condition: 5\n",
      "\n",
      " AllPub    1457\n",
      "NoSewr       2\n",
      "NoSeWa       1\n",
      "Name: Utilities, dtype: int64\n",
      "\n",
      " 0    1457\n",
      "2       2\n",
      "1       1\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mciniello\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# SELECT COLUMNS WITH OBJECT DATATPYES (SUPER USEFUL!!!)\n",
    "text_cols = df_no_mv.select_dtypes(include=['object']).columns\n",
    "\n",
    "# PRINT THE NUMBER OF UNIQUE VALUES FOR EACH OBJECT COLUMNS\n",
    "for col in text_cols:\n",
    "    print(col+\":\", len(train[col].unique()))\n",
    "\n",
    "# CONVERT OBJECT COLUMNS TO CATEGORY COLUMNS\n",
    "for col in text_cols:\n",
    "    train[col] = train[col].astype('category')\n",
    "\n",
    "# PRINT 'UTILITIES' VALUE_COUNTS (BOTH DIRECTLY AND AS CATEGORIES)\n",
    "print('\\n',train['Utilities'].value_counts())\n",
    "print('\\n',train['Utilities'].cat.codes.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dummy Coding\n",
    "\n",
    "When we convert a column to the categorical data type, pandas assigns a number from 0 to n-1 (where n is the number of unique values in a column) for each value. The drawback with this approach is that one of the assumptions of linear regression is violated here. Linear regression operates under the assumption that the features are linearly correlated with the target column. For a categorical feature, however, there's no actual numerical meaning to the categorical codes that pandas assigned for that colum. An increase in the Utilities column from 1 to 2 has no correlation value with the target column, and the categorical codes are instead used for uniqueness and exclusivity (the category associated with 0 is different than the one associated with 1).\n",
    "\n",
    "The common solution is to use a technique called dummy coding. Instead of having a single column with n integer codes, we have n binary columns. \n",
    "\n",
    "<font color = red>**Pandas thankfully has a convenience method to help us apply this transformation for all of the text columns called pandas.get_dummies():**\n",
    "\n",
    "    dummy_cols = pd.get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_cols = pd.DataFrame()\n",
    "for col in text_cols:\n",
    "    col_dummies = pd.get_dummies(train[col])\n",
    "    train = pd.concat([train, col_dummies], axis=1)\n",
    "    del train[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Transforming Improper Numerical Features\n",
    "In the last few screens, we focused on categorical values that were represented as text columns. Some of the numerical columns in the data set are also categorical and only have a limited set of unique values. We won't explicitly explore those coumns in this mission, but the feature transformation process is the same if the numbers used in those categories have no numerical meaning.\n",
    "\n",
    "Let's now look at numerical features that aren't categorical, but whose numerical representation needs to be improved. We'll focus on the Year Remod/Add and Year Built columns:\n",
    "\n",
    "    >>>train[['Year Remod/Add', 'Year Built']]\n",
    "    0   1960    1960\n",
    "    1   1961    1961\n",
    "    2   1958    1958\n",
    "    3   1968    1968\n",
    "    4   1998    1997\n",
    "    ...\n",
    "The two main issues with these features are:\n",
    "\n",
    "- Year values aren't representative of how old a house is\n",
    "- The Year Remod/Add column doesn't actually provide useful information for a linear regression model\n",
    "\n",
    "The challenge with year values like 1960 and 1961 is that they don't do a good capture how old a house is. For example, a house that was built in 1960 but sold in 1980 was sold in half the time one built in 1960 and sold in 2000. Instead of the years certain events happened, we want the difference between those years. We should create a new column that's the difference between both of these columns.\n",
    "\n",
    "For this particular piece of information (years until remodeled), this is a sensible approach. **Domain knowledge can help you understand how to best transform features to represent information well for a linear model. If you're ever confused about a feature or how it should be represented, reading scientific papers or posts by researchers in the specific domain is critical. <font color = red> Many winners of the Kaggle data science competition, for example, claim that their focus on data preparation and feature engineering combined with common machine learning models helped them win.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['years_until_remod'] = train['Year Remod/Add'] - train['Year Built']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Missing Values\n",
    "\n",
    "In the next few screens, we'll focus on handling columns with missing values. When values are missing in a column, there are two main approaches we can take:\n",
    "\n",
    "- Remove rows containing missing values for specific columns\n",
    "  - Pro: Rows containing missing values are removed, leaving only clean data for modeling\n",
    "  - Con: Entire observations from the training set are removed, which can reduce overall prediction accuracy\n",
    "- Impute (or replace) missing values using a descriptive statistic from the column\n",
    "  - Pro: Missing values are replaced with potentially similar estimates, preserving the rest of the observation in the model.\n",
    "  - Con: Depending on the approach, we may be adding noisy data for the model to learn\n",
    "\n",
    "**Given that we only have 1460 training examples (with ~80 potentially useful features), we don't want to remove any of these rows from the dataset. Let's instead focus on imputation techniques.**\n",
    "\n",
    "We'll focus on columns that contain at least 1 missing value but less than 365 missing values (or 25% of the number of rows in the training set). There's no strict threshold, and many people instead use a 50% cutoff (if half the values in a column are missing, it's automatically dropped). Having some domain knowledge can help with determining an acceptable cutoff value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lot Frontage      249\n",
      "Mas Vnr Type       11\n",
      "Mas Vnr Area       11\n",
      "Bsmt Qual          40\n",
      "Bsmt Cond          40\n",
      "Bsmt Exposure      41\n",
      "BsmtFin Type 1     40\n",
      "BsmtFin SF 1        1\n",
      "BsmtFin Type 2     41\n",
      "BsmtFin SF 2        1\n",
      "Bsmt Unf SF         1\n",
      "Total Bsmt SF       1\n",
      "Bsmt Full Bath      1\n",
      "Bsmt Half Bath      1\n",
      "Garage Type        74\n",
      "Garage Yr Blt      75\n",
      "Garage Finish      75\n",
      "Garage Qual        75\n",
      "Garage Cond        75\n",
      "dtype: int64\n",
      "Lot Frontage      float64\n",
      "Mas Vnr Type       object\n",
      "Mas Vnr Area      float64\n",
      "Bsmt Qual          object\n",
      "Bsmt Cond          object\n",
      "Bsmt Exposure      object\n",
      "BsmtFin Type 1     object\n",
      "BsmtFin SF 1      float64\n",
      "BsmtFin Type 2     object\n",
      "BsmtFin SF 2      float64\n",
      "Bsmt Unf SF       float64\n",
      "Total Bsmt SF     float64\n",
      "Bsmt Full Bath    float64\n",
      "Bsmt Half Bath    float64\n",
      "Garage Type        object\n",
      "Garage Yr Blt     float64\n",
      "Garage Finish      object\n",
      "Garage Qual        object\n",
      "Garage Cond        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('AmesHousing.txt', delimiter=\"\\t\")\n",
    "train = data[0:1460]\n",
    "test = data[1460:]\n",
    "\n",
    "train_null_counts = train.isnull().sum()\n",
    "df_missing_values = train[train_null_counts[(train_null_counts>0) & (train_null_counts<584)].index]\n",
    "\n",
    "print(df_missing_values.isnull().sum())\n",
    "print(df_missing_values.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Imputing Missing Values\n",
    "It looks like about half of the columns in df_missing_values are string columns (object data type), while about half are float64 columns. For numerical columns with missing values, a common strategy is to compute the mean, median, or mode of each column and replace all missing values in that column with that value.\n",
    "\n",
    "Because imputation is a common task, pandas contains a method named pandas.DataFrame.fillna() that we can use for this. If we pass in a value, all of the missing values (NaN) in the data frame are replaced by that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lot Frontage      0\n",
      "Mas Vnr Area      0\n",
      "BsmtFin SF 1      0\n",
      "BsmtFin SF 2      0\n",
      "Bsmt Unf SF       0\n",
      "Total Bsmt SF     0\n",
      "Bsmt Full Bath    0\n",
      "Bsmt Half Bath    0\n",
      "Garage Yr Blt     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "float_cols = df_missing_values.select_dtypes(include=['float'])\n",
    "float_cols = float_cols.fillna(df_missing_values.mean())\n",
    "print(float_cols.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Next Steps\n",
    "In this mission, we explored a few different techniques for transforming features into appropriate representations for a linear regression model. Next in this course is a guided project, where you'll practice the techniques you've learned in this course to build better linear regression models.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
