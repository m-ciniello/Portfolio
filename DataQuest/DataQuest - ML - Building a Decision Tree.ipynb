{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Intro to the data\n",
    "\n",
    "In the last mission, we used a data set on U.S. income from the 1994 census; we'll continue using it here. It contains information on marital status, age, type of work, and more. The target column, high_income, indicates a salary less than or equal to 50k per year (0), or more than 50k per year (1).\n",
    "\n",
    "You can download the data from the University of California, Irvine's website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Overview of the ID3 algorithm\n",
    "\n",
    "In the last mission, we learned about the basics of decision trees, including entropy and information gain. In this mission, we'll build on those concepts to construct a full decision tree in Python and use it make predictions.\n",
    "\n",
    "We'll use the ID3 Algorithm for constructing decision trees to accomplish this. This algorithm involves recursion and an understanding of time complexity. If you're unfamiliar with these topics, we suggest trying our Data Structures and Algorithms course. We also suggest learning about lambda functions through our command line course.\n",
    "\n",
    "In general, recursion is the process of splitting a large problem into smaller chunks. Recursive functions will call themselves, then combine the results into a final output.\n",
    "\n",
    "Building a tree is a perfect use case for recursive algorithms. At each node, we'll call a recursive function that will split the data into two branches. Each branch will lead to a node, and the function will call itself to build the tree out.\n",
    "\n",
    "We've created a pseudocode version of the full ID3 Algorithm below. Pseudocode is a plain-text outline of a piece of code that explains how it works. Exploring the pseudocode for an algorithm is a good way to understand it better before trying to code it.\n",
    "\n",
    "    def id3(data, target, columns)\n",
    "        1 Create a node for the tree\n",
    "        2 If all values of the target attribute are 1, Return the node, with label = 1\n",
    "        3 If all values of the target attribute are 0, Return the node, with label = 0\n",
    "        4 Using information gain, find A, the column that splits the data best\n",
    "        5 Find the median value in column A\n",
    "        6 Split column A into values below or equal to the median (0), and values above the median (1)\n",
    "        7 For each possible value (0 or 1), vi, of A,\n",
    "            8 Add a new tree branch below Root that corresponds to rows of data where A = vi\n",
    "            9 Let Examples(vi) be the subset of examples that have the value vi for A\n",
    "           10 Below this new branch add the subtree id3(data[A==vi], target, columns)\n",
    "           11 Return Root\n",
    "       \n",
    "We've made a minor modification to the algorithm so that it only creates two branches from each node. This will simplify the process of constructing the tree, and make it easier to demonstrate the principles it involves.\n",
    "\n",
    "The recursive nature of the algorithm comes into play on line 10. Every node in the tree will call the id3() function, and the final tree will be the result of all of these calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Walking through an example of the ID3 algorithm\n",
    "Let's make ID3 easier to follow by walking through an example with a dummy data set. We want to predict high_income using age and marital_status. In the marital_status column, 0 means unmarried, 1 means married, and 2 means divorced.\n",
    "\n",
    "    high_income    age    marital_status\n",
    "    0              20     0\n",
    "    0              60     2\n",
    "    0              40     1\n",
    "    1              25     1\n",
    "    1              35     2\n",
    "    1              55     1\n",
    "We start with our algorithm: There are both 0s and 1s in high_income, so we skip lines 2 and 3. We jump to line 4. We won't go through the information gain calculations here, but the column we split on is age.\n",
    "On line 5, we find the median, which is 37.5.\n",
    "Per line 6, we make everything less than or equal to the median 0, and anything greater than the median 1. Next, we start the loop on line 7. Because we're going through the possible values for A in order, we hit the 0 values first. We make a branch going to the left for rows of data where age <= 37.5.\n",
    "We reach line 10, and call id3() on the new node at the end of that branch. We \"pause\" this current execution of id3() because we called the function again. We'll call this paused state Node 1.\n",
    "\n",
    "The following diagram illustrates this chain of events. We've numbered the nodes in the bottom right corner.\n",
    "\n",
    "![](node2.png)\n",
    "\n",
    "The new node has the following data:\n",
    "\n",
    "    high_income    age    marital_status\n",
    "    0              20     0\n",
    "    1              25     1\n",
    "    1              35     2\n",
    "Because we recursively called the id3() function on line 10, we start over at the top, with only the post-split data. We skip lines 2 and 3 again, and find another variable to split on. age is again the best split variable, with a median of 25. We make a branch to the left where age <= 25.\n",
    "\n",
    "![](node3.png)\n",
    "\n",
    "The new node has the following data:\n",
    "\n",
    "    high_income    age    marital_status\n",
    "    0              20     0\n",
    "    1              25     1\n",
    "We'll hit line 10 again, and \"pause\" node 2 to start over in the id3() function. We find that the best column to split on is again age, and the median is 22.5.\n",
    "\n",
    "We perform another split:\n",
    "\n",
    "![](node4.png)\n",
    "\n",
    "All of the values for high_income in node 4 are 0. This means that line 3 applies, and we don't continue building the tree lower. This causes the id3 function for node 4 to return. This \"unpauses\" the id3() function for node 3, which then moves on to building the right side of the tree. Line 7 specifies that we're in a for loop. When the id3() algorithm for node 4 returns, node 3 goes to the next iteration in the for loop, which is the right branch.\n",
    "\n",
    "We're now on node 5, which is the right side of the split we make from node 3. This calls the id3() function for node 5, which stops at line 2 and returns. There's only one row in this split, and we end up with a leaf node again, where the label is 1.\n",
    "\n",
    "![](node5.png)\n",
    "\n",
    "We're done with the entire loop for node 3. We've constructed a left-hand subtree and a right-hand subtree, both of which end in terminal leaves having only one value for the target column.\n",
    "\n",
    "The id3() function for node 3 now hits line 11 and returns. This \"unpauses\" node 2, where we construct the right split. There's only one row here -- the 35 year old. This again creates a leaf node, which will have the label 1.\n",
    "\n",
    "![](node6.png)\n",
    "\n",
    "This causes node 2 to finish processing and return on line 11. This causes node 1 to \"unpause\" and start building the right side of the tree.\n",
    "\n",
    "We won't build out the entire right side of the tree right now. Instead, we'll dive into some code that will construct trees automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Determining the Column to Split On\n",
    "\n",
    "In the last mission, we wrote functions to calculate entropy and information gain. We've loaded these functions in as calc_entropy() and calc_information_gain().\n",
    "\n",
    "Now we need a function that returns the name of the column we should use to split a data set. The function should take the name of the data set, the target column, and a list of columns we might want to split on as input.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Write a function named find_best_column() that returns the name of a column to split the data on. We've started to define this function for you.\n",
    "- Use find_best_column() to find the best column on which to split income.\n",
    "- The target is the high_income column, and the potential columns to split with are in the list columns below.\n",
    "- Assign the result to income_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass  fnlwgt   education  education_num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38            Private  215646     HS-grad              9   \n",
      "3   53            Private  234721        11th              7   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital_status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital_gain  capital_loss  hours_per_week  native_country high_income  \n",
      "0          2174             0              40   United-States       <=50K  \n",
      "1             0             0              13   United-States       <=50K  \n",
      "2             0             0              40   United-States       <=50K  \n",
      "3             0             0              40   United-States       <=50K  \n",
      "4             0             0              40            Cuba       <=50K  \n",
      "0    7\n",
      "1    6\n",
      "2    4\n",
      "3    4\n",
      "4    4\n",
      "Name: workclass, dtype: int8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mciniello\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:8: FutureWarning: Categorical.from_array is deprecated, use Categorical instead\n",
      "C:\\Users\\mciniello\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:12: FutureWarning: Categorical.from_array is deprecated, use Categorical instead\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "# Set index_col to False to avoid pandas thinking that the first column is row indexes (it's age)\n",
    "income = pandas.read_csv(\"income.csv\", index_col=False)\n",
    "print(income.head(5))\n",
    "\n",
    "# Convert a single column from text categories to numbers\n",
    "col = pandas.Categorical.from_array(income[\"workclass\"])\n",
    "income[\"workclass\"] = col.codes\n",
    "print(income[\"workclass\"].head(5))\n",
    "for name in [\"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\", \"high_income\"]:\n",
    "    col = pandas.Categorical.from_array(income[name])\n",
    "    income[name] = col.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "# first re-load the entropy function\n",
    "def calc_entropy(column):\n",
    "    \"\"\"\n",
    "    Calculate entropy given a pandas series, list, or numpy array.\n",
    "    \"\"\"\n",
    "    # Compute the counts of each unique value in the column\n",
    "    counts = np.bincount(column)\n",
    "    # Divide by the total column length to get a probability\n",
    "    probabilities = counts / len(column)\n",
    "    \n",
    "    # Initialize the entropy to 0\n",
    "    entropy = 0\n",
    "    # Loop through the probabilities, and add each one to the total entropy\n",
    "    for prob in probabilities:\n",
    "        if prob > 0:\n",
    "            entropy += prob * math.log(prob, 2)\n",
    "    \n",
    "    return -entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_information_gain(data, split_name, target_name):\n",
    "    \"\"\"\n",
    "    Calculate information gain given a data set, column to split on, and target\n",
    "    \"\"\"\n",
    "    # Calculate the original entropy\n",
    "    original_entropy = calc_entropy(data[target_name])\n",
    "    \n",
    "    # Find the median of the column we're splitting\n",
    "    column = data[split_name]\n",
    "    median = column.median()\n",
    "    \n",
    "    # Make two subsets of the data, based on the median\n",
    "    left_split = data[column <= median]\n",
    "    right_split = data[column > median]\n",
    "    \n",
    "    # Loop through the splits and calculate the subset entropies\n",
    "    to_subtract = 0\n",
    "    for subset in [left_split, right_split]:\n",
    "        prob = (subset.shape[0] / data.shape[0]) \n",
    "        to_subtract += prob * calc_entropy(subset[target_name])\n",
    "    \n",
    "    # Return information gain\n",
    "    return original_entropy - to_subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"age\", \"workclass\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"hours_per_week\", \"native_country\"]\n",
    "def find_best_column(data, target_name, columns):\n",
    "    information_gains = []\n",
    "    # Loop through and compute information gains\n",
    "    for col in columns:\n",
    "        information_gain = calc_information_gain(data, col, \"high_income\")\n",
    "        information_gains.append(information_gain)\n",
    "\n",
    "    # Find the name of the column with the highest gain\n",
    "    highest_gain_index = information_gains.index(max(information_gains))\n",
    "    highest_gain = columns[highest_gain_index]\n",
    "    return highest_gain\n",
    "\n",
    "income_split = find_best_column(income, \"high_income\", columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Creating a Simple Recursive Algorithm\n",
    "\n",
    "Let's build up to making the full id3() function by creating a simpler algorithm that we can extend. Here's what that algorithm looks like in pseudocode:\n",
    "\n",
    "    def id3(data, target, columns)\n",
    "        1 Create a node for the tree\n",
    "        2 If all values of the target attribute are 1, add 1 to counter_1\n",
    "        3 If all values of the target attribute are 0, add 1 to counter_0\n",
    "        4 Using information gain, find A, the column that splits the data best\n",
    "        5 Find the median value in column A\n",
    "        6 Split A into values below or equal to the median (0), and values above the median (1)\n",
    "        7 For each possible value (0 or 1), vi, of A,\n",
    "        8    Add a new tree branch below Root that corresponds to rows of data where A = vi\n",
    "        9    Let Examples(vi) be the subset of examples that have the value vi for A\n",
    "       10    Below this new branch, add the subtree id3(data[A==vi], target, columns)\n",
    "       11 Return Root\n",
    "\n",
    "This version is very similar to the algorithm above, but lines 2 and 3 are different. Rather than storing the entire tree (which is a bit complicated), we'll just tally how many leaves end up with the label 1, and how many end up with the label 0.\n",
    "\n",
    "We'll replicate this algorithm in code, and apply it to the same data set we just stepped through on a previous screen:\n",
    "\n",
    "    high_income    age    marital_status\n",
    "    0              20     0\n",
    "    0              60     2\n",
    "    0              40     1\n",
    "    1              25     1\n",
    "    1              35     2\n",
    "    1              55     1\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Read the id3() function below and fill in the lines that say \"Insert code here...\".\n",
    "    - The function should append 1 to label_1s if the node should be a leaf, and only has 1s for high_income.\n",
    "    - It should append 0 to label_0s if the node should be a leaf, and only has 0s for high_income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use lists to store our labels for nodes (when we find them)\n",
    "# Lists can be accessed inside our recursive function, whereas integers can't.  \n",
    "# Look at the python missions on scoping for more information on this topic\n",
    "label_1s = []\n",
    "label_0s = []\n",
    "\n",
    "def id3(data, target, columns):\n",
    "    unique_targets = pandas.unique(data[target])\n",
    "\n",
    "    if len(unique_targets) == 1:\n",
    "        if 0 in unique_targets:\n",
    "            label_0s.append(0)\n",
    "        elif 1 in unique_targets:\n",
    "            label_1s.append(1)\n",
    "        return\n",
    "    \n",
    "    best_column = find_best_column(data, target, columns)\n",
    "    column_median = data[best_column].median()\n",
    "    \n",
    "    left_split = data[data[best_column] <= column_median]\n",
    "    right_split = data[data[best_column] > column_median]\n",
    "    \n",
    "    for split in [left_split, right_split]:\n",
    "        id3(split, target, columns)\n",
    "\n",
    "\n",
    "id3(data, \"high_income\", [\"age\", \"marital_status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Storing the tree\n",
    "\n",
    "Now we can store the entire tree, rather than the leaf labels only. We'll use nested dictionaries to do this. We can represent the root node with a dictionary, and branches with the keys left and right. We'll store the column we're splitting on as the key column, and the median value as the key median. Finally, we can store the label for a leaf as the key label. We'll also number each node as we go along using the number key.\n",
    "\n",
    "    We'll use the same data set we've been working with:\n",
    "\n",
    "    high_income    age    marital_status\n",
    "    0              20     0\n",
    "    0              60     2\n",
    "    0              40     1\n",
    "    1              25     1\n",
    "    1              35     2\n",
    "    1              55     1\n",
    "Here's what the dictionary for the decision tree will look like:\n",
    "\n",
    "    {  \n",
    "       \"left\":{  \n",
    "          \"left\":{  \n",
    "             \"left\":{  \n",
    "                \"number\":4,\n",
    "                \"label\":0\n",
    "             },\n",
    "             \"column\":\"age\",\n",
    "             \"median\":22.5,\n",
    "             \"number\":3,\n",
    "             \"right\":{  \n",
    "                \"number\":5,\n",
    "                \"label\":1\n",
    "             }\n",
    "          },\n",
    "          \"column\":\"age\",\n",
    "          \"median\":25.0,\n",
    "          \"number\":2,\n",
    "          \"right\":{  \n",
    "             \"number\":6,\n",
    "             \"label\":1\n",
    "          }\n",
    "       },\n",
    "       \"column\":\"age\",\n",
    "       \"median\":37.5,\n",
    "       \"number\":1,\n",
    "       \"right\":{  \n",
    "          \"left\":{  \n",
    "             \"left\":{  \n",
    "                \"number\":9,\n",
    "                \"label\":0\n",
    "             },\n",
    "             \"column\":\"age\",\n",
    "             \"median\":47.5,\n",
    "             \"number\":8,\n",
    "             \"right\":{  \n",
    "                \"number\":10,\n",
    "                \"label\":1\n",
    "             }\n",
    "          },\n",
    "          \"column\":\"age\",\n",
    "          \"median\":55.0,\n",
    "          \"number\":7,\n",
    "          \"right\":{  \n",
    "             \"number\":11,\n",
    "             \"label\":0\n",
    "          }\n",
    "       }\n",
    "    }\n",
    "If we look at node 2 (the left branch of the root node), we see that it matches the hand exercise we completed a few screens ago. It splits, creating a right branch (node 6) with the label 1, and a left branch (node 3) that splits again.\n",
    "\n",
    "In order to keep track of the tree, we'll need to make some modifications to id3(). The first modification involves changing the definition to pass in the tree dictionary:\n",
    "\n",
    "    def id3(data, target, columns, tree)\n",
    "        1 Create a node for the tree\n",
    "        2 Number the node\n",
    "        3 If all of the values of the target attribute are 1, assign 1 to the label key in tree\n",
    "        4 If all of the values of the target attribute are 0, assign 0 to the label key in tree\n",
    "        5 Using information gain, find A, the column that splits the data best\n",
    "        6 Find the median value in column A\n",
    "        7 Assign the column and median keys in tree\n",
    "        8 Split A into values less than or equal to the median (0), and values above the median (1)\n",
    "        9 For each possible value (0 or 1), vi, of A,\n",
    "       10    Add a new tree branch below Root that corresponds to rows of data where A = vi\n",
    "       11    Let Examples(vi) be the subset of examples that have the value vi for A\n",
    "       12    Create a new key with the name corresponding to the side of the split (0=left, 1=right).  The value of this key should be an empty dictionary.\n",
    "       13    Below this new branch, add the subtree id3(data[A==vi], target, columns, tree[split_side])\n",
    "       14 Return Root\n",
    "       \n",
    "Under this approach, we're now passing the tree dictionary into our id3 function and setting some keys on it. One complexity is in how we're creating the nested dictionary. For the left split, we're adding a key to the tree dictionary that looks like this:\n",
    "\n",
    "tree[\"left\"] = {}\n",
    "\n",
    "For the right side, we're adding:\n",
    "\n",
    "tree[\"right\"] = {}\n",
    "\n",
    "Now that we've added this key, we're able to pass our new dictionary into the recursive call to id3(). While this new dictionary will be the dictionary for that specific node, it will be tied back to the parent dictionary (because it's a key of the original dictionary).\n",
    "\n",
    "This process will continue building up the nested dictionary. We'll be able to access the entire dictionary using the variable tree we define before the function. Think of each recursive call as building a piece of the tree, which we can then access after all of the functions have terminated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Storing the tree\n",
    "Instructions\n",
    "\n",
    "Fill in the sections labelled \"Insert code here...\" in the id3() function.\n",
    "- The first section should assign the correct label to the tree dictionary.\n",
    "    - You can do this by setting the label key equal to the correct label.\n",
    "- The second section should assign the column and median keys to the tree dictionary.\n",
    "    - The values should be equal to best_column and column_median.\n",
    "\n",
    "Finally, call the id3 function with the correct inputs -- id3(data, \"high_income\", [\"age\", \"marital_status\"], tree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = {}\n",
    "nodes = []\n",
    "\n",
    "def id3(data, target, columns, tree):\n",
    "    unique_targets = pandas.unique(data[target])\n",
    "    nodes.append(len(nodes) + 1)\n",
    "    tree[\"number\"] = nodes[-1]\n",
    "\n",
    "    if len(unique_targets) == 1:\n",
    "        if 0 in unique_targets:\n",
    "            tree[\"label\"] = 0\n",
    "        elif 1 in unique_targets:\n",
    "            tree[\"label\"] = 1\n",
    "        return\n",
    "    \n",
    "    best_column = find_best_column(data, target, columns)\n",
    "    column_median = data[best_column].median()\n",
    "    \n",
    "    tree[\"column\"] = best_column\n",
    "    tree[\"median\"] = column_median\n",
    "    \n",
    "    left_split = data[data[best_column] <= column_median]\n",
    "    right_split = data[data[best_column] > column_median]\n",
    "    split_dict = [[\"left\", left_split], [\"right\", right_split]]\n",
    "    \n",
    "    for name, split in split_dict:\n",
    "        tree[name] = {}\n",
    "        id3(split, target, columns, tree[name])\n",
    "\n",
    "\n",
    "id3(data, \"high_income\", [\"age\", \"marital_status\"], tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Printing Labels for a more Attractive Tree\n",
    "\n",
    "The tree dictionary shows all of the relevant information, but it doesn't look very nice. We can fix its appearance by printing it out in a nicer format.\n",
    "\n",
    "To do this, we'll need to recursively iterate through our tree dictionary. Any dictionary that has a label key is a leaf. Whenever we find one, we'll print out the label. Otherwise, we'll loop through the tree's left and right keys and recursively call the same function.\n",
    "\n",
    "We also need to keep track of a depth variable. This variable will allow us to use indentation to indicate the order of the nodes. Before we print anything out, we'll prefix it with the number of spaces corresponding to the depth variable.\n",
    "\n",
    "Here's the pseudocode:\n",
    "\n",
    "    def print_node(tree, depth):\n",
    "        1 Check for the presence of the \"label\" key in the tree\n",
    "        2     If found, print the label and return\n",
    "        3 Print out the tree's \"column\" and \"median\" keys\n",
    "        4 Iterate through the tree's \"left\" and \"right\" keys\n",
    "        5     Recursively call print_node(tree[key], depth+1)\n",
    "**Instructions:**\n",
    "\n",
    "Fill in the gaps in the print_node() function that say \"Insert code here...\".\n",
    "- Your code should iterate through both branches of the branches list (in order), and recursively call print_node().\n",
    "    - Don't forget to increment depth when you call print_node.\n",
    "\n",
    "Call print_node(), and pass in tree and depth 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age > 37.5\n",
      "    age > 25.0\n",
      "        age > 22.5\n",
      "            Leaf: Label 0\n",
      "            Leaf: Label 1\n",
      "        Leaf: Label 1\n",
      "    age > 55.0\n",
      "        age > 47.5\n",
      "            Leaf: Label 0\n",
      "            Leaf: Label 1\n",
      "        Leaf: Label 0\n"
     ]
    }
   ],
   "source": [
    "def print_with_depth(string, depth):\n",
    "    # Add space before a string\n",
    "    prefix = \"    \" * depth\n",
    "    # Print a string, and indent it appropriately\n",
    "    print(\"{0}{1}\".format(prefix, string))\n",
    "    \n",
    "    \n",
    "def print_node(tree, depth):\n",
    "    if \"label\" in tree:\n",
    "        print_with_depth(\"Leaf: Label {0}\".format(tree[\"label\"]), depth)\n",
    "        return\n",
    "    print_with_depth(\"{0} > {1}\".format(tree[\"column\"], tree[\"median\"]), depth)\n",
    "    for branch in [tree[\"left\"], tree[\"right\"]]:\n",
    "        print_node(branch, depth+1)\n",
    "\n",
    "print_node(tree, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Making prediction with the Printed Tree\n",
    "\n",
    "Now that we've printed the tree out, we can see what the split points are:\n",
    "\n",
    "    age > 37.5\n",
    "        age > 25.0\n",
    "            age > 22.5\n",
    "                Leaf: Label 0\n",
    "                Leaf: Label 1\n",
    "            Leaf: Label 1\n",
    "        age > 55.0\n",
    "            age > 47.5\n",
    "                Leaf: Label 0\n",
    "                Leaf: Label 1\n",
    "            Leaf: Label 0\n",
    "The left branch prints out first, then the right branch. Each node prints the criteria on which it was split. Can you tell how to predict a new value by looking at this tree?\n",
    "\n",
    "Let's say we want to predict the following row:\n",
    "\n",
    "    age    marital_status\n",
    "    50     1\n",
    "    \n",
    "First, we'd split on age > 37.5 and go to the right. Then, we'd split on age > 55.0 and go to the left. Then, we'd split on age > 47.5 and go to the right. We'd end up predicting a 1 for high_income.\n",
    "\n",
    "Making predictions with such a small tree is fairly straightforward, but what if we want to use the entire income dataframe? We wouldn't be able to eyeball predictions; we'd want an automated way to do this instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Making Predictions Automatically\n",
    "\n",
    "Let's write a function that makes predictions automatically. All we need to do is follow the split points we've already defined with a new row.\n",
    "\n",
    "Here's the pseudocode:\n",
    "\n",
    "    def predict(tree, row):\n",
    "        1 Check for the presence of \"label\" in the tree dictionary\n",
    "        2    If found, return tree[\"label\"]\n",
    "        3 Extract tree[\"column\"] and tree[\"median\"]\n",
    "        4 Check whether row[tree[\"column\"]] is less than or equal to tree[\"median\"]\n",
    "        5    If it's less than or equal, call predict(tree[\"left\"], row) and return the result\n",
    "        6    If it's greater, call predict(tree[\"right\"], row) and return the result\n",
    "        \n",
    "The major difference here is that we're returning values. Because we're only calling the function recursively once in each iteration (we only go \"down\" a single branch), we can return a single value up the chain of recursion. This will let us get a value back when we call the function.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "Fill in the gaps in the predict() function that say \"Insert code here...\".\n",
    "- The code should check whether row[column] is less than or equal to median, and return the appropriate result for each side of the tree.\n",
    "- Print the result of predicting the first row of the data with predict(tree, data.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def predict(tree, row):\n",
    "    if \"label\" in tree:\n",
    "        return tree[\"label\"]\n",
    "    \n",
    "    column = tree[\"column\"]\n",
    "    median = tree[\"median\"]\n",
    "    if row[column] <= median:\n",
    "        return predict(tree[\"left\"], row)\n",
    "    else:\n",
    "        return predict(tree[\"right\"], row)\n",
    "\n",
    "print(predict(tree, data.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Making Multiple Predictions\n",
    "\n",
    "Now that we can make a prediction for a single row, we can write a function that makes predictions for multiple rows simultanously.\n",
    "\n",
    "To do this, we'll use the apply() method on pandas dataframes to apply a function across each row. You can read more about the function in the pandas documentation. You'll need to pass in the axis=1 argument to apply the function to each row. This method will return a dataframe.\n",
    "\n",
    "You can use the apply() method along with lambda functions to apply the predict() function to each row of new_data.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "Create a function named batch_predict() that takes two parameters, tree and df.\n",
    "- It should use the apply() method to apply the predict() function across each row of df.\n",
    "    - You can use lambda functions to pass tree and row into predict.\n",
    "\n",
    "Call batch_predict() with new_data as the parameter df, and assign the result to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "5    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pandas.DataFrame([\n",
    "    [40,0],\n",
    "    [20,2],\n",
    "    [80,1],\n",
    "    [15,1],\n",
    "    [27,2],\n",
    "    [38,1]\n",
    "    ])\n",
    "# Assign column names to the data\n",
    "new_data.columns = [\"age\", \"marital_status\"]\n",
    "\n",
    "def batch_predict(tree, df):\n",
    "    return df.apply(lambda x: predict(tree, x), axis=1)\n",
    "\n",
    "predictions = batch_predict(tree, new_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Next Steps\n",
    "In this mission, we learned how to create a full decision tree model, print the results, and use the tree to make predictions. We applied a modified version of the ID3 algorithm on a small data set for clarity.\n",
    "\n",
    "In future missions, we'll apply decision trees across larger data sets, learn the trade-offs associated with different algorithms, and explore how to generate more accurate predictions from decision trees."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
