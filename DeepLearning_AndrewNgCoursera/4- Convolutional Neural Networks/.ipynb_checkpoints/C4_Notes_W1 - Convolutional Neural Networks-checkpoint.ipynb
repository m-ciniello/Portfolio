{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "**C4_Notes_W1 - Convolutional Neural Networks**\n",
    "\n",
    "This is the forth course of the deep learning specialization at [Coursera](https://www.coursera.org/specializations/deep-learning) which is moderated by [DeepLearning.ai](http://deeplearning.ai/). The course is taught by Andrew Ng.\n",
    "\n",
    "## Course summary\n",
    "\n",
    "Here is the course summary as given on the course [link](https://www.coursera.org/learn/convolutional-neural-networks):\n",
    "\n",
    "> This course will teach you how to build convolutional neural networks and apply it to image data. Thanks to deep learning, computer vision is working far better than just two years ago, and this is enabling numerous exciting applications ranging from safe autonomous driving, to accurate face recognition, to automatic reading of radiology images. \n",
    ">\n",
    "> You will:\n",
    "> - Understand how to build a convolutional neural network, including recent variations such as residual networks.\n",
    "> - Know how to apply convolutional networks to visual detection and recognition tasks.\n",
    "> - Know to use neural style transfer to generate art.\n",
    "> - Be able to apply these algorithms to a variety of image, video, and other 2D or 3D data.\n",
    ">\n",
    "> This is the fourth course of the Deep Learning Specialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Week 1: Foundations of CNNs**\n",
    "\n",
    "Learn to implement the foundational layers of CNNs (pooling, convolutions) and to stack them properly in a deep network to solve multi-class image classification problems\n",
    "\n",
    "  * [1. Computer vision](#computer-vision)\n",
    "  * [2. Edge detection example](#edge-detection-example)\n",
    "  * [3. Padding](#padding)\n",
    "  * [4. Strided convolution](#strided-convolution)\n",
    "  * [5. Convolutions over volumes](#convolutions-over-volumes)\n",
    "  * [6. One Layer of a Convolutional Network](#one-layer-of-a-convolutional-network)\n",
    "  * [7. A simple convolution network example](#a-simple-convolution-network-example)\n",
    "  * [8. Pooling layers](#pooling-layers)\n",
    "  * [9. Convolutional neural network example](#convolutional-neural-network-example)\n",
    "  * [10. Why convolutions?](#why-convolutions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision\n",
    "\n",
    "\n",
    "- Computer vision is one of the applications that are rapidly active thanks to deep learning.\n",
    "- Some of the applications of computer vision that are using deep learning includes:\n",
    "  - Self driving cars.\n",
    "  - Face recognition.\n",
    "- Deep learning is also enabling new types of art to be created.\n",
    "- Rapid changes to computer vision are making new applications that weren't possible a few years ago.\n",
    "- Computer vision deep leaning techniques are always evolving making a new architectures which can help us in other areas other than computer vision.\n",
    "  - For example, Andrew Ng took some ideas of computer vision and applied it in speech recognition.\n",
    "- Examples of a computer vision problems includes:\n",
    "  - Image classification.\n",
    "  - Object detection.\n",
    "    - Detect object and localize them.\n",
    "  - Neural style transfer\n",
    "    - Changes the style of an image using another image.\n",
    "- One of the challenges of computer vision problem that images can be so large and we want a fast and accurate algorithm to work with that.\n",
    "  - For example, a `1000x1000` image will represent 3 million feature/input to the full connected neural network. If the following hidden layer contains 1000, then we will want to learn weights of the shape `[1000, 3 million]` which is 3 billion parameter only in the first layer and thats so computationally expensive!\n",
    "- One of the solutions is to build this using **convolution layers** instead of the **fully connected layers**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge detection example\n",
    "\n",
    "- The convolution operation is one of the fundamentals blocks of a CNN. One of the examples about convolution is the image edge detection operation.\n",
    "- Early layers of CNN might detect edges then the middle layers will detect parts of objects and the later layers will put the these parts together to produce an output.\n",
    "- In an image we can detect vertical edges, horizontal edges, or full edge detector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical Edge Detection\n",
    "\n",
    "![](Images/01.png)\n",
    "- In the last example a `6x6` matrix convolved with `3x3` filter/kernel gives us a `4x4` matrix.\n",
    "  - If you make the convolution operation in TensorFlow you will find the function `tf.nn.conv2d`. In keras you will find `Conv2d` function.\n",
    "\n",
    "**How does this work?**\n",
    "\n",
    "Basically, the vertical edge detection filter will find a `3x3` place in an image where there are a bright region followed by a dark region.\n",
    " - If we applied this filter to a white region followed by a dark region, it should find the edges in between the two colors as a positive value. \n",
    " - But if we applied the same filter to a dark region followed by a white region it will give us negative values. To solve this we can use the abs function to make it positive.\n",
    "  \n",
    "Lets look at another example:\n",
    "![](Images/C4_Notes_W1_vertline.jpg)\n",
    "\n",
    "- Note that the reason the 'edge' looks so thick (the two columns of 30s) is because we are using such small images. But this gives you a general idea of how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More advanced edge detection\n",
    "- Just as we can use a filter to detect vertical edges, we can use a similar filter to detect horizontal edges:\n",
    "\n",
    "![](Images/C4_Notes_W1_03.jpg)\n",
    "\n",
    "- There are also a bunch of other filters that we can use that are a bit more complex, like the Sobel and Schorr filters. \n",
    "- What we learned in the deep learning is that **we don't need to hand craft these numbers,** we can treat them as weights and then LEARN THEM. It can learn horizontal, vertical, angled, or any edge type automatically rather than getting them by hand.\n",
    "![](Images/C4_Notes_W1_04.jpg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding\n",
    "- In order to to use deep neural networks we really need to use **paddings**.\n",
    "- In the last section we saw that a `6x6` matrix convolved with `3x3` filter/kernel gives us a `4x4` matrix.\n",
    "- To give it a general rule, if a matrix `nxn` is convolved with `fxf` filter/kernel give us `n-f+1,n-f+1` matrix. \n",
    "- The convolution operation shrinks the matrix if f>1.\n",
    "- We want to apply convolution operation multiple times, but if the image shrinks we will lose a lot of data on this process. Also the edges pixels are used less than other pixels in an image.\n",
    "- So the problems with convolutions are:\n",
    "  - Shrinks output.\n",
    "  - throwing away a lot of information that are in the edges.\n",
    "- To solve these problems we can pad the input image before convolution by adding some rows and columns to it. We will call the padding amount `P` the number of row/columns that we will insert in top, bottom, left and right of the image.\n",
    "![](Images/C4_Notes_W1_05.jpg)\n",
    "\n",
    "- In almost all the cases the padding values are zeros.\n",
    "- The general rule now,  if a matrix `nxn` is convolved with `fxf` filter/kernel and padding `p` give us `n+2p-f+1,n+2p-f+1` matrix. \n",
    "- If n = 6, f = 3, and p = 1 Then the output image will have `n+2p-f+1 = 6+2-3+1 = 6`. We maintain the size of the image6\n",
    "\n",
    "- There are two main types of padding techniques, **Valid** and **Same** padding:\n",
    "    - Valid means ZERO padding\n",
    "    - Same means we add enough padding to keep the output the same size as the input: `  P = (f-1) / 2`\n",
    "\n",
    "![](Images/C4_Notes_W1_06.jpg)\n",
    "\n",
    "\n",
    "- NOTE: In computer vision **f (the size of the filter or kernel) is usually odd**. Some of the reasons is that its have a center value (otherwise you may need non-semetrical padding).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strided convolution\n",
    "\n",
    "- Strided convolution is another piece that are used in CNNs.\n",
    "\n",
    "- We will call stride `S`.\n",
    "\n",
    "- When we are making the convolution operation we used `S` to tell us the number of pixels we will jump when we are convolving filter/kernel. The last examples we described S was 1.\n",
    "\n",
    "- Now the general rule are:\n",
    "  -  if a matrix `nxn` is convolved with `fxf` filter/kernel and padding `p` and stride `s` it give us `(n+2p-f)/s + 1,(n+2p-f)/s + 1` matrix. \n",
    "\n",
    "- In case `(n+2p-f)/s + 1` is fraction we can take **floor** of this value.\n",
    "\n",
    "- In math textbooks the conv operation is filpping the filter before using it. What we were doing is called cross-correlation operation but the state of art of deep learning is using this as conv operation.\n",
    "\n",
    "- We can still use the `same padding`  technique to keep the output size the same as the input size. Its given by the equation:\n",
    "\n",
    "  ```\n",
    "  p = (n*s - n + f - s) / 2\n",
    "  When s = 1 ==> P = (f-1) / 2\n",
    "  ```\n",
    "  \n",
    " ![](Images/C4_Notes_W1_07.jpg)\n",
    " ![](Images/C4_Notes_W1_08.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions over volumes\n",
    "\n",
    "- We see how convolution works with 2D images, now lets see if we want to convolve 3D images (RGB image)\n",
    "- We will convolve an image of height, width, **# of channels (RGD: Red, Blue, Green)** with a filter size of a height, width, same # of channels. **Note that the image number channels and the filter number of channels are the same.**\n",
    " ![](Images/C4_Notes_W1_09.jpg)\n",
    "- We essentially stack our filters to match the number of channels in the original image **(these filters can be different for each chanel)**\n",
    "- Example:\n",
    "  - Input image: `6x6x3`\n",
    "  - Filter: `3x3x3`\n",
    "  - Result image: `4x4x1`\n",
    "  - In the last result p=0, s=1\n",
    "- Note the output here is only 2D.\n",
    "- We can use multiple filters to detect multiple features or edges. Example.\n",
    "  - Input image: `6x6x3`\n",
    "  - 10 Filters: `3x3x3`\n",
    "  - Result image: `4x4x10`\n",
    "  - In the last result p=0, s=1\n",
    " \n",
    " ![](Images/C4_Notes_W1_10.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Layer of a Convolutional Network\n",
    "\n",
    "- First we convolve some filters to a given input and then add a bias to each filter output and then get RELU of the result. Example:\n",
    "  - Input image: `6x6x3`         `# a0`\n",
    "  - 10 Filters: `3x3x3`         `#W1`\n",
    "  - Result image: `4x4x10`     `#W1a0`\n",
    "  - Add b (bias) with `10x1` will get us : `4x4x10` image      `#W1a0 + b`\n",
    "  - Apply RELU will get us: `4x4x10` image                `#A1 = RELU(W1a0 + b)`\n",
    "  - In the last result p=0, s=1\n",
    "  - Hint number of parameters here are: `(3x3x3x10) + 10 = 280`\n",
    "- The last example forms a layer in the CNN.\n",
    "- Note that **no matter the size of the input, the number of the parameters is same if filter size is same. That makes it less prone to overfitting.** This is also super handy for large images, as adding a weight for each pixel could get very computationally comples\n",
    "![](Images/C4_Notes_W1_11.jpg)\n",
    "\n",
    "\n",
    "- Here is the notation we will use. If layer l is a conv layer:\n",
    "\n",
    "  ```\n",
    "  Hyperparameters\n",
    "  f[l] = filter size\n",
    "  p[l] = padding\t# Default is zero\n",
    "  s[l] = stride\n",
    "  nc[l] = number of filters\n",
    "\n",
    "  Input:  n[l-1] x n[l-1] x nc[l-1]\tOr\t nH[l-1] x nW[l-1] x nc[l-1]\n",
    "  Output: n[l] x n[l] x nc[l]\tOr\t nH[l] x nW[l] x nc[l]\n",
    "  Where n[l] = (n[l-1] + 2p[l] - f[l] / s[l]) + 1\n",
    "\n",
    "  Each filter is: f[l] x f[l] x nc[l-1]\n",
    "\n",
    "  Activations: a[l] is nH[l] x nW[l] x nc[l]\n",
    "  \t\t     A[l] is m x nH[l] x nW[l] x nc[l]   # In batch or minbatch training\n",
    "  \t\t     \n",
    "  Weights: f[l] * f[l] * nc[l-1] * nc[l]\n",
    "  bias:  (1, 1, 1, nc[l])\n",
    "  ```\n",
    "  \n",
    "  ![](Images/C4_Notes_W1_12.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple convolution network example\n",
    "- Lets build a big example.\n",
    "  - Input Image are:   `a0 = 39x39x3`\n",
    "    - `n0 = 39` and `nc0 = 3`\n",
    "  - First layer (Conv layer):\n",
    "    - `f1 = 3`, `s1 = 1`, and `p1 = 0`\n",
    "    - `number of filters = 10`\n",
    "    - Then output are `a1 = 37x37x10`\n",
    "      - `n1 = 37` and `nc1 = 10`\n",
    "  - Second layer (Conv layer):\n",
    "    - `f2 = 5`, `s2 = 2`, `p2 = 0`\n",
    "    - `number of filters = 20`\n",
    "    - The output are `a2 = 17x17x20`\n",
    "      - `n2 = 17`, `nc2 = 20`\n",
    "    - Hint shrinking goes much faster because the stride is 2\n",
    "  - Third layer (Conv layer):\n",
    "    - `f3 = 5`, `s3 = 2`, `p2 = 0`\n",
    "    - `number of filters = 40`\n",
    "    - The output are `a3 = 7x7x40`\n",
    "      - `n3 = 7`, `nc3 = 40`\n",
    "  - Forth layer (Fully connected Softmax)\n",
    "    - `a3 = 7x7x40 = 1960`  as a vector..\n",
    "    \n",
    "  ![](Images/C4_Notes_W1_13.jpg)\n",
    "\n",
    "- In the last example you seen that the image are getting smaller after each layer and thats the trend now.\n",
    "- Types of layer in a convolutional network:\n",
    "  - Convolution. \t\t`#Conv`\n",
    "  - Pooling      `#Pool`\n",
    "  - Fully connected     `#FC`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling layers\n",
    "\n",
    "- Other than the conv layers, CNNs often uses pooling layers to reduce the size of the inputs, speed up computation, and to make some of the features it detects more robust.\n",
    "- Max pooling example:\n",
    "![](Images/02.png)\n",
    "    - This example has `f = 2`, `s = 2`, and `p = 0` hyperparameters\n",
    "- The basic idea behind max pooling is that if the feature is detected anywhere in this filter then keep a high number. But the main reason why people are using pooling because its works well in practice and **reduce computations.**\n",
    "- Its very important to not that **Max pooling has no parameters to learn.**\n",
    "- Example of Max pooling on 3D input:\n",
    "  - Input: `4x4x10`\n",
    "  - `Max pooling size = 2` and `stride = 2`\n",
    "  - Output: `2x2x10`\n",
    "- Average pooling is taking the averages of the values instead of taking the max values.\n",
    "- Max pooling is used more often than average pooling in practice.\n",
    "- If stride of pooling equals the size, it will then apply the effect of shrinking.\n",
    "- Hyperparameters summary\n",
    "  - f : filter size.\n",
    "  - s : stride.\n",
    "  - Padding is rarely used with Max Pooling.\n",
    "  - Max or average pooling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network example\n",
    "\n",
    "- Now we will deal with a full CNN example. This example is something like the ***LeNet-5*** that was invented by Yann Lecun.\n",
    "  - Input Image are:   `a0 = 32x32x3` (RGB image)\n",
    "    - `n0 = 32` and `nc0 = 3`\n",
    "  - First layer (Conv layer):        `#Conv1`\n",
    "    - `f1 = 5`, `s1 = 1`, and `p1 = 0`\n",
    "    - `number of filters = 6`\n",
    "    - Then output are `a1 = 28x28x6`\n",
    "      - `n1 = 28` and `nc1 = 6`\n",
    "    - Then apply (Max pooling):         `#Pool1`\n",
    "      - `f1p = 2`, and `s1p = 2`\n",
    "      - The output are `a1 = 14x14x6`\n",
    "  - Second layer (Conv layer):   `#Conv2`\n",
    "    - `f2 = 5`, `s2 = 1`, `p2 = 0`\n",
    "    - `number of filters = 16`\n",
    "    - The output are `a2 = 10x10x16`\n",
    "      - `n2 = 10`, `nc2 = 16`\n",
    "    - Then apply (Max pooling):         `#Pool2`\n",
    "      - `f1p = 2`, and `s1p = 2`\n",
    "      - The output are `a2 = 5x5x16`\n",
    "  - Third layer (Fully connected)   `#FC3`\n",
    "    - Number of neurons are 120\n",
    "    - The output `a3 = 120 x 1` . 400 came from `5x5x16`\n",
    "  - Forth layer (Fully connected)  `#FC4`\n",
    "    - Number of neurons are 84\n",
    "    - The output `a4 = 84 x 1` .\n",
    "  - Fifth layer (Softmax)\n",
    "    - Number of neurons is 10 if we need to identify for example the 10 digits.\n",
    "- Hint a Conv1 and Pool1 is treated as one layer.\n",
    "- Some statistics about the last example:\n",
    "  - ![](Images/03.png)\n",
    "- Hyperparameters are a lot. For choosing the value of each you should follow the guideline that we will discuss later or check the literature and takes some ideas and numbers from it.\n",
    "- Usually the input size decreases over layers while the number of filters increases.\n",
    "- A CNN usually consists of one or more convolution (Not just one as the shown examples) followed by a pooling.\n",
    "- Fully connected layers has the most parameters in the network.\n",
    "- To consider using these blocks together you should look at other working examples firsts to get some intuitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why convolutions?\n",
    "\n",
    "- Two main advantages of Convs are:\n",
    "  - Parameter sharing.\n",
    "    - A feature detector (such as a vertical edge detector) that's useful in one part of the image is probably useful in another part of the image.\n",
    "  - sparsity of connections.\n",
    "    - In each layer, each output value depends only on a small number of inputs which makes it translation invariance.\n",
    "- Putting it all together:\n",
    "![](Images/04.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
