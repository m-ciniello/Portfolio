{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import csv\n",
    "#import paramaters\n",
    "from parsel import Selector\n",
    "from time import sleep\n",
    "from time import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Engineer': 3, 'Infrastructure': 2, 'Mining': 1, 'PMP': 4, 'alala': 5}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = [('Mining',9), ('Infrastructure',7), ('Engineer',6), ('PMP',5)]\n",
    "\n",
    "range_ = range(1,len(terms))\n",
    "{term: rank for term, rank in zip(terms,range(1,len(terms)+1))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mining And Infrastructure And Engineer And PMP And alala'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" And \".join(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-211-1eba69d8d8ab>, line 112)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-211-1eba69d8d8ab>\"\u001b[1;36m, line \u001b[1;32m112\u001b[0m\n\u001b[1;33m    unique_links = self.get_unique_links(self.final_dict)\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class googlelink_ranks():\n",
    "    def __init__(self,position,location,firms,secondary_terms):\n",
    "        self.position = position\n",
    "        self.location = location\n",
    "        self.firms = firms\n",
    "        self.secondary_terms = secondary_terms\n",
    "        self.search_criteria_dict = { \"positions\" : self.position , \"location\" : self.location ,\n",
    "                                     \"firms\" : self.firms , \"secondary_terms\" : self.secondary_terms.keys() }\n",
    "    \n",
    "    def custom_sleep(self, min_=4,max_=9):\n",
    "        sleep(randint(min_,max_)+np.random.rand())\n",
    "        \n",
    "    def construct_search(self):\n",
    "        # ADD QUOTES\n",
    "        add_quotes = lambda term: '\"'+term+'\"'\n",
    "        for key, var in self.search_criteria_dict.items():\n",
    "            self.search_criteria_dict[key] = list(map(add_quotes, var))\n",
    "\n",
    "        # ADD SEARCH TERMS TO BASE\n",
    "        for key, var in self.search_criteria_dict.items():\n",
    "            if key == 'secondary_terms':\n",
    "                continue\n",
    "            self.search_criteria_dict[key] = ' OR '.join(var)\n",
    "        \n",
    "        # Base term + secondary terms\n",
    "        search_dict = {}\n",
    "        base_term = 'site:linkedin.com/in/'\n",
    "        for term in self.search_criteria_dict['secondary_terms']:\n",
    "            extended_term = base_term + \" \" + self.search_criteria_dict[\"positions\"] + \" AND \" + term + \" AND \" + self.search_criteria_dict['firms'] + \" AND \" + self.search_criteria_dict['location']   \n",
    "            search_dict[term.strip('\"')] = extended_term  #search_dict is a dictionary with key: secondary terms and value is the link \n",
    "        self.search_dict = search_dict\n",
    "        \n",
    "    def get_profile_links(self,query, google_pages=10, headless=True, path='chromedriver'):\n",
    "        ############ INITIALIZE RANDOM SEED ############\n",
    "        np.random.seed(randint(1000))\n",
    "        ############ INITIALIZE DRIVER ############\n",
    "        options = webdriver.ChromeOptions()\n",
    "        if headless:\n",
    "            options.add_argument('headless')\n",
    "        #set drive\n",
    "        driver = webdriver.Chrome(executable_path=path, chrome_options=options)\n",
    "        t0_full = time()\n",
    "\n",
    "        ############ RUN GOOGLE QUERY ############\n",
    "        print(\"Running google query: {} \".format(query))\n",
    "        driver.get('https://www.google.com')\n",
    "        self.custom_sleep()\n",
    "        search_query = driver.find_element_by_name('q')\n",
    "        search_query.send_keys(query)\n",
    "        self.custom_sleep()\n",
    "        search_query.send_keys(Keys.RETURN)\n",
    "\n",
    "        ############ SCRAPE GOOGLE LINKS ############\n",
    "        linkedin_urls = []\n",
    "        for i in range(google_pages):\n",
    "            t0 = time()\n",
    "            linkedin_urls_single = driver.find_elements_by_tag_name('cite')\n",
    "            linkedin_urls_single = [(url.text,i+1) for url in linkedin_urls_single]\n",
    "            linkedin_urls += linkedin_urls_single\n",
    "            self.custom_sleep()\n",
    "            print(\"Scrape page {} complete, runtime = {}\".format(i+1,time()-t0), end=\"\\r\")\n",
    "            max_page= i+1\n",
    "            try:\n",
    "                next_page = driver.find_element_by_xpath('//*[@id=\"pnnext\"]')\n",
    "                next_page.click()\n",
    "            except:\n",
    "                break\n",
    "            \n",
    "        print(\"{0} google pages scraped. Full script runtime = {1}\".format(max_page,time() - t0_full))\n",
    "        return linkedin_urls\n",
    "\n",
    "    def get_links_dict(self):\n",
    "        # Extract google search link for every secondary search term\n",
    "        final_dict = {}\n",
    "        for key in self.search_dict:\n",
    "            final_dict[key] = self.get_profile_links(query = self.search_dict[key]) #final_dict's keys correspond to secondary terms and values correspond to links wihtin its secondary tern search respective\n",
    "        return final_dict\n",
    "        \n",
    "    def get_unique_links(self, tuple_dict):\n",
    "        # Extract list of unique links\n",
    "        unique_links = set()\n",
    "        for key,val in tuple_dict.items():\n",
    "            unique_links.update([tup[0] for tup in val]) #converting a dictionary of links to a list of unique links\n",
    "        return unique_links\n",
    "    \n",
    "    def extract_score(self, unique_links, final_dict, alpha=0.5):\n",
    "        # Extract scores and links\n",
    "        link_list = []\n",
    "        for link in unique_links: \n",
    "            final_score = 0 #scoring links based on the number of search 'pool' they fall into\n",
    "            category = [] #labeling links on which search category they appear in\n",
    "            for key, tuples in final_dict.items():\n",
    "                only_links = [tup[0] for tup in tuples]\n",
    "                if link in only_links:\n",
    "                    # Extract second element of corresponding link (page occured in google) \n",
    "                    page_occured = tuples[only_links.index(link)][1]\n",
    "                    term_rank = self.secondary_terms[key]\n",
    "                    term_score = ((1/page_occured)*alpha) + ((term_rank/10)*(1-alpha))\n",
    "                    final_score+= term_score\n",
    "                    category.append((key, page_occured, term_rank, term_score))\n",
    "            #converting each link with their scores and category to a tuple\n",
    "            link_list.append((link,final_score,category)) # each tuple should have format (str, int, list)\n",
    "        return link_list\n",
    "            \n",
    "    def construct_final_list(self, existing_data=None): \n",
    "        if existing_data==None:\n",
    "            self.final_dict = self.get_links_dict()\n",
    "        else:\n",
    "            # LOAD IN EXISTING DATA\n",
    "            ################# WRITE CODE HERE #####################\n",
    "        # Extract unique links\n",
    "        unique_links = self.get_unique_links(self.final_dict) \n",
    "        # Extract scores\n",
    "        link_tuples = self.extract_score(unique_links, self.final_dict)\n",
    "        return link_tuples\n",
    "        \n",
    "    def write_csv(self):\n",
    "        with open('ScrapingResults.csv', 'wb') as f:  # Just use 'w' mode in 3.x\n",
    "            w = csv.DictWriter(f, self.final_dict.keys())\n",
    "            w.writeheader()\n",
    "            w.writerow(self.final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://www.linkedin.com/in/kristen-palmer-cpa-ca-pmp-7921811a',\n",
       " 0.41666666666666663,\n",
       " [('PMP', 3, 5)])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running google query: site:linkedin.com/in/ \"Senior manager\" OR \"Director\" AND \"Mining\" AND \"PwC\" OR \"Deloitte\" OR \"EY\" AND \"Toronto\" \n",
      "10 google pages scraped. Full script runtime = 92.73594355583191\n",
      "Running google query: site:linkedin.com/in/ \"Senior manager\" OR \"Director\" AND \"Infrastructure\" AND \"PwC\" OR \"Deloitte\" OR \"EY\" AND \"Toronto\" \n",
      "10 google pages scraped. Full script runtime = 84.68955659866333\n",
      "Running google query: site:linkedin.com/in/ \"Senior manager\" OR \"Director\" AND \"Engineer\" AND \"PwC\" OR \"Deloitte\" OR \"EY\" AND \"Toronto\" \n",
      "10 google pages scraped. Full script runtime = 92.92075896263123\n",
      "Running google query: site:linkedin.com/in/ \"Senior manager\" OR \"Director\" AND \"PMP\" AND \"PwC\" OR \"Deloitte\" OR \"EY\" AND \"Toronto\" \n",
      "10 google pages scraped. Full script runtime = 96.580326795578\n"
     ]
    }
   ],
   "source": [
    "positions = ['Senior manager', 'Director']\n",
    "locations = ['Toronto']\n",
    "firm = ['PwC', 'Deloitte', 'EY']\n",
    "\n",
    "secondary_terms = {'Mining':9,\n",
    "                   'Infrastructure':7, \n",
    "                   'Engineer':6,\n",
    "                   'PMP':5}\n",
    "\n",
    "scrape_links = googlelink_ranks(positions,locations,firm,secondary_terms)\n",
    "scrape_links.construct_search()\n",
    "tuples = scrape_links.construct_final_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tuples, columns=['link','score','terms'])\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "df2 = df.sort_values('score',ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('Exec_search_mining.xlsx')\n",
    "df2.to_excel(writer, 'sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Senior manager\" OR \"Director\"\n",
      "\"Toronto\"\n",
      "\"PwC\" OR \"Deloitte\" OR \"EY\"\n",
      "\"Mining\"\n",
      "\"Engineer\"\n",
      "\"PMP\"\n",
      "Running google query: site:linkedin.com/in/ \"Senior manager\" OR \"Director\" AND \"Mining\" AND \"PwC\" OR \"Deloitte\" OR \"EY\" AND \"Toronto\" \n",
      "10 google pages scraped. Full script runtime = 86.38096499443054\n",
      "Running google query: site:linkedin.com/in/ \"Senior manager\" OR \"Director\" AND \"Engineer\" AND \"PwC\" OR \"Deloitte\" OR \"EY\" AND \"Toronto\" \n",
      "10 google pages scraped. Full script runtime = 96.21447777748108\n",
      "Running google query: site:linkedin.com/in/ \"Senior manager\" OR \"Director\" AND \"PMP\" AND \"PwC\" OR \"Deloitte\" OR \"EY\" AND \"Toronto\" \n",
      "10 google pages scraped. Full script runtime = 89.18608021736145\n"
     ]
    }
   ],
   "source": [
    "positions = ['Senior manager', 'Director']\n",
    "locations = ['Toronto']\n",
    "firm = ['PwC', 'Deloitte', 'EY']\n",
    "secondary_terms = ['Mining', 'Engineer' , 'PMP']\n",
    "\n",
    "scrape_links = googlelink_ranks(positions,locations,firm,secondary_terms)\n",
    "scrape_links.construct_links()\n",
    "scrape_links.construct_final_list()\n",
    "#scrape_links.link_list\n",
    "#scrape_links.write_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>score</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://ca.linkedin.com/in/mary-sanagan-664b6017</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"PMP\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ca.linkedin.com/in/jlising</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"Mining\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://ca.linkedin.com/in/macmcdonald1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"Mining\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://ca.linkedin.com/in/mikesamis-scmdecisi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"Mining\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/in/kristen-palmer-cpa...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"PMP\"]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  score       terms\n",
       "0   https://ca.linkedin.com/in/mary-sanagan-664b6017      1     [\"PMP\"]\n",
       "1                 https://ca.linkedin.com/in/jlising      1  [\"Mining\"]\n",
       "2            https://ca.linkedin.com/in/macmcdonald1      1  [\"Mining\"]\n",
       "3  https://ca.linkedin.com/in/mikesamis-scmdecisi...      1  [\"Mining\"]\n",
       "4  https://www.linkedin.com/in/kristen-palmer-cpa...      1     [\"PMP\"]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(scrape_links.link_list, columns=['link','score','terms'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
