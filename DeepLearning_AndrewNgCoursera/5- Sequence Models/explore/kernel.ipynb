{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "6a308a82c3fa78fc270d765cfb4b9cb1dd05aec7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "PATH = '../input'\n",
    "df = pd.read_csv(f'{PATH}/train.csv')\n",
    "X, y = df.iloc[:100000,1], df.iloc[:100000,2]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dd110a9e0fb65b9d8b7d37164f9b59d7977503d8"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "57e83bc897cdb24a3539de5a24f0c8b451e15aee"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "vectorizer = TfidfVectorizer(strip_accents=None,lowercase=True, preprocessor=None, tokenizer=None, analyzer='word', \n",
    "                             stop_words=stopwords,token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 3), max_df=1.0, min_df=1,\n",
    "                             max_features=None, vocabulary=None, binary=False, norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "\n",
    "# Fit vectorizer\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "# Transform training and test sets\n",
    "X_train_vect = vectorizer.transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "72353a64f8dd88a0ea3e68a31deb92806c2c5a44"
   },
   "source": [
    "- **class sklearn.svm.SVC**(C=1.0, kernel=’rbf’, degree=3, gamma=’auto_deprecated’, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=’ovr’, random_state=None)[source]¶\n",
    "- **class sklearn.ensemble.RandomForestClassifier**(n_estimators=’warn’, criterion=’gini’, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None)\n",
    "- **class sklearn.ensemble.GradientBoostingClassifier**(loss=’deviance’, learning_rate=0.1, n_estimators=100, subsample=1.0, criterion=’friedman_mse’, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort=’auto’, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "63e14169117636d2255ab97a985974fc94d86a76"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3df897dff8353ee28f862da06397bff1ec5afcab"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "class_weights = {0:1,1:24}\n",
    "mod1 = SVC(C=1.0, kernel='rbf', class_weight=class_weights)\n",
    "mod2 = RandomForestClassifier(class_weight=class_weights)\n",
    "mod3 = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b62e782cbd65ce42b54bd8d520e36eff10e4d054"
   },
   "outputs": [],
   "source": [
    "mod1.fit(X_train_vect, y_train)\n",
    "y_pred = mod1.predict(X_test_vect)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aa6730f188ddb74be437db555b5db0c3addf5d9b"
   },
   "outputs": [],
   "source": [
    "mod2.fit(X_train_vect, y_train)\n",
    "y_pred = mod1.predict(X_test_vect)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fbcedca62fbc78899dbe742f9b996ab128a075fc"
   },
   "outputs": [],
   "source": [
    "mod3.fit(X_train_vect, y_train)\n",
    "y_pred = mod1.predict(X_test_vect)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0b31395e194a464d1c01d0244e5f326d170bbf06"
   },
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import TruncatedSVD\n",
    "#svd = TruncatedSVD(algorithm='randomized', n_components=4400, n_iter=7, random_state=42, tol=0.0)\n",
    "#data_reduced = svd.fit(data)\n",
    "#print(svd.explained_variance_ratio_)  # doctest: +ELLIPSIS\n",
    "#print(svd.explained_variance_ratio_.sum())  # doctest: +ELLIPSIS\n",
    "#print(svd.singular_values_)  # doctest: +ELLIPSIS\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
