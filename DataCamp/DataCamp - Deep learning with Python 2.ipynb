{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with wider networks\n",
    "\n",
    "Now you know everything you need to begin experimenting with different models!\n",
    "\n",
    "A model called model_1 has been pre-loaded (**JK YOU HAVE TO REMAKE BELOW LOLZ**). You can see a summary of this model printed in the IPython Shell. This is a relatively small network, with only 10 units in each hidden layer.\n",
    "\n",
    "In this exercise you'll create a new model called model_2 which is similar to model_1, except it has 100 units in each hidden layer.\n",
    "\n",
    "After you create model_2, both models will be fitted, and a graph showing both models loss score at each epoch will be shown. We added the argument verbose=False in the fitting commands to print out fewer updates, since you will look at these graphically instead of as text.\n",
    "\n",
    "Because you are fitting two models, it will take a moment to see the outputs after you hit run, so be patient.\n",
    "\n",
    "**Instructions:**\n",
    "- Create model_2 to replicate model_1, but use 100 nodes instead of 10 for the first two Dense layers you add with the 'relu' activation. Use 2 nodes for the Dense output layer with 'softmax' as the activation.\n",
    "- Compile model_2 as you have done with previous models: Using 'adam' as the optimizer, 'categorical_crossentropy' for the loss, and metrics=['accuracy'].\n",
    "- Hit 'Submit Answer' to fit both the models and visualize which one gives better results! Notice the keyword argument verbose=False in model.fit(): This prints out fewer updates, since you'll be evaluating the models graphically instead of through text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>male</th>\n",
       "      <th>age_was_missing</th>\n",
       "      <th>embarked_from_cherbourg</th>\n",
       "      <th>embarked_from_queenstown</th>\n",
       "      <th>embarked_from_southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  male age_was_missing  \\\n",
       "0         0       3  22.0      1      0   7.2500     1           False   \n",
       "1         1       1  38.0      1      0  71.2833     0           False   \n",
       "2         1       3  26.0      0      0   7.9250     0           False   \n",
       "3         1       1  35.0      1      0  53.1000     0           False   \n",
       "4         0       3  35.0      0      0   8.0500     1           False   \n",
       "\n",
       "   embarked_from_cherbourg  embarked_from_queenstown  \\\n",
       "0                        0                         0   \n",
       "1                        1                         0   \n",
       "2                        0                         0   \n",
       "3                        0                         0   \n",
       "4                        0                         0   \n",
       "\n",
       "   embarked_from_southampton  \n",
       "0                          1  \n",
       "1                          0  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 22.0 1 0 7.25 1 False 0 0 1]\n",
      " [1 38.0 1 0 71.2833 0 False 1 0 0]\n",
      " [3 26.0 0 0 7.925 0 False 0 0 1]\n",
      " [1 35.0 1 0 53.1 0 False 0 0 1]\n",
      " [3 35.0 0 0 8.05 1 False 0 0 1]]\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# convert data from DataFrame to matrix (predictors).\n",
    "# we don't need to convert target to a matrix, as the to_categorical function will do that for us\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "predictor_cols = ['pclass', 'age', 'sibsp', 'parch', 'fare', 'male',\n",
    "       'age_was_missing', 'embarked_from_cherbourg',\n",
    "       'embarked_from_queenstown', 'embarked_from_southampton']\n",
    "\n",
    "predictors = df[predictor_cols].as_matrix()\n",
    "\n",
    "# get number of input nodes\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Convert the target to categorical: target\n",
    "target = to_categorical(df.survived)\n",
    "\n",
    "print(predictors[0:5])\n",
    "print(target[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 242\n",
      "Trainable params: 242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(10, activation='relu', input_shape = input_shape))\n",
    "model_1.add(Dense(10, activation='relu'))\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time for model_2!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/15\n",
      "712/712 [==============================] - 0s - loss: 3.9792 - acc: 0.6096 - val_loss: 3.2366 - val_acc: 0.6425\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/15\n",
      "712/712 [==============================] - 0s - loss: 2.8886 - acc: 0.6096 - val_loss: 2.1700 - val_acc: 0.6425\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/15\n",
      "712/712 [==============================] - 0s - loss: 1.4362 - acc: 0.4410 - val_loss: 0.8072 - val_acc: 0.4078\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/15\n",
      "712/712 [==============================] - 0s - loss: 0.7731 - acc: 0.5112 - val_loss: 0.5700 - val_acc: 0.7374\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/15\n",
      "712/712 [==============================] - 0s - loss: 0.6851 - acc: 0.6475 - val_loss: 0.5674 - val_acc: 0.7318\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/15\n",
      "712/712 [==============================] - 0s - loss: 0.6658 - acc: 0.6615 - val_loss: 0.5596 - val_acc: 0.7374\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/15\n",
      "712/712 [==============================] - 0s - loss: 0.6596 - acc: 0.6292 - val_loss: 0.5535 - val_acc: 0.7374\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/15\n",
      "712/712 [==============================] - 0s - loss: 0.6447 - acc: 0.6728 - val_loss: 0.5426 - val_acc: 0.7709\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/15\n",
      "712/712 [==============================] - 0s - loss: 0.6264 - acc: 0.6742 - val_loss: 0.5327 - val_acc: 0.7598\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/15\n",
      "712/712 [==============================] - 0s - loss: 0.6224 - acc: 0.6896 - val_loss: 0.5321 - val_acc: 0.7654\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/15\n",
      "712/712 [==============================] - 0s - loss: 0.6197 - acc: 0.6742 - val_loss: 0.5306 - val_acc: 0.7709\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/15\n",
      "712/712 [==============================] - 0s - loss: 0.6141 - acc: 0.6854 - val_loss: 0.5322 - val_acc: 0.7709\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/15\n",
      "712/712 [==============================] - 0s - loss: 0.6118 - acc: 0.6896 - val_loss: 0.5254 - val_acc: 0.7765\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/15\n",
      "712/712 [==============================] - 0s - loss: 0.6086 - acc: 0.6924 - val_loss: 0.5274 - val_acc: 0.7709\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/15\n",
      "712/712 [==============================] - 0s - loss: 0.6067 - acc: 0.6924 - val_loss: 0.5211 - val_acc: 0.7765\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/15\n",
      "712/712 [==============================] - 0s - loss: 0.8045 - acc: 0.6404 - val_loss: 0.5112 - val_acc: 0.7430\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/15\n",
      "712/712 [==============================] - 0s - loss: 0.6398 - acc: 0.6699 - val_loss: 0.5978 - val_acc: 0.7095\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/15\n",
      "712/712 [==============================] - 0s - loss: 0.6035 - acc: 0.6812 - val_loss: 0.5057 - val_acc: 0.6872\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/15\n",
      "712/712 [==============================] - 0s - loss: 0.5782 - acc: 0.7107 - val_loss: 0.5766 - val_acc: 0.6369\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/15\n",
      "712/712 [==============================] - 0s - loss: 0.6125 - acc: 0.6924 - val_loss: 0.5275 - val_acc: 0.7430\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/15\n",
      "712/712 [==============================] - 0s - loss: 0.6072 - acc: 0.7163 - val_loss: 0.4658 - val_acc: 0.7933\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/15\n",
      "712/712 [==============================] - 0s - loss: 0.5477 - acc: 0.7163 - val_loss: 0.4936 - val_acc: 0.7877\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/15\n",
      "712/712 [==============================] - 0s - loss: 0.5404 - acc: 0.7360 - val_loss: 0.5120 - val_acc: 0.7598\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/15\n",
      "712/712 [==============================] - 0s - loss: 0.5489 - acc: 0.7402 - val_loss: 0.4610 - val_acc: 0.8045\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/15\n",
      "712/712 [==============================] - 0s - loss: 0.5594 - acc: 0.7317 - val_loss: 0.5700 - val_acc: 0.6760\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/15\n",
      "712/712 [==============================] - 0s - loss: 0.5618 - acc: 0.7360 - val_loss: 0.4857 - val_acc: 0.7989\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/15\n",
      "712/712 [==============================] - 0s - loss: 0.5780 - acc: 0.7360 - val_loss: 0.4623 - val_acc: 0.7486\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3v8HYMIRQXmaCTIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe5734a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first and second layers\n",
    "model_2.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(100, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model_1\n",
    "model_1_training = model_1.fit(predictors, target, \n",
    "                               epochs=15, \n",
    "                               validation_split=0.2, \n",
    "                               callbacks=[early_stopping_monitor], \n",
    "                               verbose=True)\n",
    "\n",
    "# Fit model_2\n",
    "model_2_training = model_2.fit(predictors, target, \n",
    "                               epochs=15, \n",
    "                               validation_split=0.2, \n",
    "                               callbacks=[early_stopping_monitor], \n",
    "                               verbose=True)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The blue model is the one you made, the red is the original model. Your model had a lower loss value, so it is the better model. Nice job!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding layers to a network\n",
    "\n",
    "You've seen how to experiment with wider networks. In this exercise, you'll try a deeper network (more hidden layers).\n",
    "\n",
    "Once again, you have a baseline model called model_1 as a starting point. It has 1 hidden layer, with 50 units. You can see a summary of that model's structure printed out. You will create a similar network with 3 hidden layers (still keeping 50 units in each layer).\n",
    "\n",
    "This will again take a moment to fit both models, so you'll need to wait a few seconds to see the results after you run your code.\n",
    "\n",
    "**Instructions:**\n",
    "- Specify a model called model_2 that is like model_1, but which has 3 hidden layers of 50 units instead of only 1 hidden layer.\n",
    " - Use input_shape to specify the input shape in the first hidden layer.\n",
    " - Use 'relu' activation for the 3 hidden layers and 'softmax' for the output layer, which should have 2 units.\n",
    "- Compile model_2 as you have done with previous models: Using 'adam' as the optimizer, 'categorical_crossentropy' for the loss, and metrics=['accuracy'].\n",
    "- Hit 'Submit Answer' to fit both the models and visualize which one gives better results! For both models, you should look for the best val_loss and val_acc, which won't be the last epoch for that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 50)                550       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 652\n",
      "Trainable params: 652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create model_1 again\n",
    "\n",
    "# Specify the model\n",
    "model_1b = Sequential()\n",
    "model_1b.add(Dense(50, activation='relu', input_shape = input_shape))\n",
    "model_1b.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_1b.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_1b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niFRRUhARkSr/H1ezo8gbd/mYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c5ff60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the new model: model_2\n",
    "model_2b = Sequential()\n",
    "\n",
    "# Add the first, second, and third hidden layers\n",
    "model_2b.add(Dense(50,activation='relu',input_shape=input_shape))\n",
    "model_2b.add(Dense(50,activation='relu'))\n",
    "model_2b.add(Dense(50,activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2b.add(Dense(2,activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2b.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Fit model 1\n",
    "model_1_training = model_1b.fit(predictors, target, \n",
    "                                epochs=20, \n",
    "                                validation_split=0.4, \n",
    "                                callbacks=[early_stopping_monitor], \n",
    "                                verbose=False)\n",
    "\n",
    "# Fit model 2\n",
    "model_2_training = model_2b.fit(predictors, target, \n",
    "                                epochs=20, \n",
    "                                validation_split=0.4, \n",
    "                                callbacks=[early_stopping_monitor], \n",
    "                                verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video: Thinking About Model Capacity\n",
    "\n",
    "It takes some practice to get an intution for what experiments and architectures to try when tuning your deep learning models. \n",
    "\n",
    "However, model capacity should be a key consideration (also called Network Capacity). Its very closely related to overfitting and underfitting. **Remember, validation score is the ultimate measure of a models predictive quality**.\n",
    "\n",
    "![](pictures/modelcap1.png)\n",
    "\n",
    "**You can replace the Model Complexity with Model Capacity in the graph above**. Model capacity is a models ability to capture predictive patterns in your data, so the more capacity, the further to right on the grpah. If you increase the number of nodes or hidden layers, that increases model capacity. \n",
    "\n",
    "Here is a good workflow for model capcaity. \n",
    "- Start with small netrwork\n",
    "- get validaitons score\n",
    "- keep adding capacity until validation score is no longer improving\n",
    "\n",
    "There is no rule for whether you should increase nodes or layers, this is kind of more art that science! But def follow this model capacity workflow to get to the ideal model.\n",
    "\n",
    "![](pictures/modcap1.png)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building your own digit recognition model\n",
    "\n",
    "You've reached the final exercise of the course - you now know everything you need to build an accurate model to recognize handwritten digits!\n",
    "\n",
    "We've already done the basic manipulation of the MNIST dataset shown in the video, so you have X and y loaded and ready to model with. Sequential and Dense from keras are also pre-imported.\n",
    "\n",
    "To add an extra challenge, we've loaded only 2500 images, rather than 60000 which you will see in some published results. Deep learning models perform better with more data, however, they also take longer to train, especially when they start becoming more complex.\n",
    "\n",
    "If you have a computer with a CUDA compatible GPU, you can take advantage of it to improve computation time. If you don't have a GPU, no problem! You can set up a deep learning environment in the cloud that can run your models on a GPU. Here is a blog post by Dan that explains how to do this - check it out after completing this exercise!https://www.datacamp.com/community/tutorials/deep-learning-jupyter-aws#gs.z0ysHGM It is a great next step as you continue your deep learning journey.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Create a Sequential object to start your model. Call this model.\n",
    "- Add the first Dense hidden layer of 50 units to your model with 'relu' activation. For this data, the input_shape is (784,).\n",
    "- Add a second Dense hidden layer with 50 units and a 'relu' activation function.\n",
    "- Add the output layer. Your activation function should be 'softmax', and the number of nodes in this layer should be the same as the number of possible outputs in this case: 10.\n",
    "- Compile model as you have done with previous models: Using 'adam' as the optimizer, 'categorical_crossentropy' for the loss, and metrics=['accuracy'].\n",
    "- Fit the model using X and y using a validation_split of 0.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video: Stepping up to images!!!\n",
    "\n",
    "- Going to use the MNIST data set which contains images of handwritten digits. \n",
    "- each image is compose of 28 X 28 pixel grid, flattened to 784 vales for each image (one array or row for each image)\n",
    "- each value in each part of the array denotes the darkness of that pixel (0 is dark as possible, 255 is as light as possible)\n",
    "- you model will predict which digit that was written. You will create a deep learning model taking in the 784 features as inputs and predicting which of the 10 possible values the ouput is!!!\n",
    "\n",
    "**This is essentially a muli-class categorical prediction model!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('mnist.csv')\n",
    "y = to_categorical(df['5'])\n",
    "X = df.iloc[:,1:].as_matrix()\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1400 samples, validate on 600 samples\n",
      "Epoch 1/20\n",
      "1400/1400 [==============================] - 0s - loss: 12.0896 - acc: 0.2314 - val_loss: 9.9686 - val_acc: 0.3567\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/20\n",
      "1400/1400 [==============================] - 0s - loss: 9.0643 - acc: 0.4171 - val_loss: 8.1232 - val_acc: 0.4883\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/20\n",
      "1400/1400 [==============================] - 0s - loss: 8.4261 - acc: 0.4636 - val_loss: 8.3949 - val_acc: 0.4667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/20\n",
      "1400/1400 [==============================] - 0s - loss: 8.1881 - acc: 0.4836 - val_loss: 7.8285 - val_acc: 0.5050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/20\n",
      "1400/1400 [==============================] - 0s - loss: 7.7524 - acc: 0.5114 - val_loss: 7.8059 - val_acc: 0.5050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/20\n",
      "1400/1400 [==============================] - 0s - loss: 7.6987 - acc: 0.5143 - val_loss: 7.2767 - val_acc: 0.5400\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/20\n",
      "1400/1400 [==============================] - 0s - loss: 7.2211 - acc: 0.5450 - val_loss: 7.3462 - val_acc: 0.5317\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/20\n",
      "1400/1400 [==============================] - 0s - loss: 7.2360 - acc: 0.5450 - val_loss: 7.2352 - val_acc: 0.5383\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/20\n",
      "1400/1400 [==============================] - 0s - loss: 6.9154 - acc: 0.5614 - val_loss: 7.2668 - val_acc: 0.5433\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/20\n",
      "1400/1400 [==============================] - 0s - loss: 7.1347 - acc: 0.5479 - val_loss: 7.5196 - val_acc: 0.5217\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/20\n",
      "1400/1400 [==============================] - 0s - loss: 6.8004 - acc: 0.5657 - val_loss: 6.8973 - val_acc: 0.5650\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/20\n",
      "1400/1400 [==============================] - 0s - loss: 6.3863 - acc: 0.5964 - val_loss: 6.6439 - val_acc: 0.5817\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/20\n",
      "1400/1400 [==============================] - 0s - loss: 5.9628 - acc: 0.6179 - val_loss: 5.9152 - val_acc: 0.6267\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/20\n",
      "1400/1400 [==============================] - 0s - loss: 5.6164 - acc: 0.6407 - val_loss: 5.8526 - val_acc: 0.6167\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/20\n",
      "1400/1400 [==============================] - 0s - loss: 5.4769 - acc: 0.6486 - val_loss: 5.3852 - val_acc: 0.6567\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/20\n",
      "1400/1400 [==============================] - 0s - loss: 4.9534 - acc: 0.6857 - val_loss: 5.5189 - val_acc: 0.6467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/20\n",
      "1400/1400 [==============================] - 0s - loss: 4.9517 - acc: 0.6850 - val_loss: 5.2827 - val_acc: 0.6550\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/20\n",
      "1400/1400 [==============================] - 0s - loss: 5.0018 - acc: 0.6793 - val_loss: 5.1257 - val_acc: 0.6667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 0s - loss: 5.0424 - acc: 0.6761\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/20\n",
      "1400/1400 [==============================] - 0s - loss: 4.7535 - acc: 0.6971 - val_loss: 5.0369 - val_acc: 0.6800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/20\n",
      "1400/1400 [==============================] - 0s - loss: 4.6659 - acc: 0.7043 - val_loss: 4.8788 - val_acc: 0.6817\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12ae4978>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "model.add(Dense(50, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Add the second hidden layer\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y, validation_split=0.3,epochs=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So our model has a pretty low accuracy (around 50%), but we only used 1400 images to train the data. The actual set has around 60,000 images to train the data with. Apparently when you use the whole set you get SUPER high accuracy. Which is dope. Got to that blog post and use the GPU thing to test out this model with the full set and see how high you can get the accuracy to be!!!**\n",
    "\n",
    "You need a CUDE compatiable Graphical Procesing Unit (GPU). But you can use the blog post to set one up on the cloud using Jupyter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
